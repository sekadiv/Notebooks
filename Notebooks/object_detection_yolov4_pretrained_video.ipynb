{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection_yolov4_pretrained_video.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF5rGAnOF1Gm"
      },
      "source": [
        "# Object Detection using the YOLO V4 pre-trained model\n",
        "\n",
        "*by Georgios K. Ouzounis, June 10th, 2021*\n",
        "\n",
        "In this exercise we will experiment with object detection in streaming video using the YOLO V4 pretrained model. This is only a demo and will perform very slowly due to the virtual environment. For substantially improved performance compile a .py file with all the relevant code and run it locally.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB9dN1Io78DA"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXzDYD5Jqxdo"
      },
      "source": [
        "# import the relevant libraries\n",
        "import numpy as np\n",
        "import cv2 # openCV\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewrJSoXrGadW"
      },
      "source": [
        "# check the opencv version\n",
        "print(cv2.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmXkC427Gkqx"
      },
      "source": [
        "# if the openCV version is < 4.4.0 update to the latest otherwise skip this step\n",
        "!pip install opencv-python==4.5.2.52"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ms4LYX18B-1"
      },
      "source": [
        "## Get the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1TwKBXhHcXu"
      },
      "source": [
        "# first create a directory to store the model\n",
        "%mkdir model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY4WZZF1H1nZ"
      },
      "source": [
        "# enter the directory and download the necessary files \n",
        "%cd model\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
        "!wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\n",
        "!wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/data/coco.names\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRoo5k-QdB5K"
      },
      "source": [
        "## Customize the YOLO detector\n",
        "\n",
        "class labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zq2FwRd_lso"
      },
      "source": [
        "class_labels_path = \"/content/model/coco.names\"\n",
        "class_labels = open(class_labels_path).read().strip().split(\"\\n\")\n",
        "class_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJu-efpG4f8X"
      },
      "source": [
        "bounding box color definitions: two options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80wm8OWX_oxr"
      },
      "source": [
        "# declare repeating bounding box colors for each class \n",
        "# 1st: create a list colors as an RGB string array\n",
        "# Example: Red, Green, Blue, Yellow, Magenda\n",
        "class_colors = [\"255,0,0\",\"0,255,0\",\"0,0,255\",\"255,255,0\",\"255,0, 255\"]\n",
        "\n",
        "#2nd: split the array on comma-seperated strings and for change each string type to integer\n",
        "class_colors = [np.array(every_color.split(\",\")).astype(\"int\") for every_color in class_colors]\n",
        "\n",
        "#3d: convert the array or arrays to a numpy array\n",
        "class_colors = np.array(class_colors)\n",
        "\n",
        "#4th: tile this to get 80 class colors, i.e. as many as the classes  (16rows of 5cols each). \n",
        "# If you want unique colors for each class you may randomize the color generation \n",
        "# or set them manually\n",
        "class_colors = np.tile(class_colors,(16,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxNlQ1FO4mOI"
      },
      "source": [
        "or random colors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItyWr4oX4pb8"
      },
      "source": [
        "class_colors = np.random.randint(0, 255, size=(len(class_labels), 3), dtype=\"uint8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0aJYLgc1L-q"
      },
      "source": [
        "Declare remaining parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJlg76c61T1Q"
      },
      "source": [
        "# for the image2blob conversion\n",
        "scalefactor = 1.0/255.0\n",
        "new_size = (416, 416)\n",
        "\n",
        "# for the NMS\n",
        "score_threshold = 0.5\n",
        "nms_threshold = 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHo_MgL40uma"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBTX_4xYAhZc"
      },
      "source": [
        "# Load the pre-trained model \n",
        "yolo_model = cv2.dnn.readNetFromDarknet('model/yolov4.cfg','model/yolov4.weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cew-LCPDJOR"
      },
      "source": [
        "# Read the network layers/components. The YOLO V4 neural network has 379 components.\n",
        "# They consist of convolutional layers (conv), rectifier linear units (relu) etc.:\n",
        "model_layers = yolo_model.getLayerNames()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkBIXXd9E_lK"
      },
      "source": [
        "# Loop through all network layers to find the output layers\n",
        "output_layers = [model_layers[model_layer[0] - 1] for model_layer in yolo_model.getUnconnectedOutLayers()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXYCReuy5e7Q"
      },
      "source": [
        "## Run the model on the live video feed using NMS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDkah5J7zSWZ"
      },
      "source": [
        "install the following two packages to access video content  from www.yutube.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_yaBFAd9vtm"
      },
      "source": [
        "!pip install pafy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZK7xtAF94oW"
      },
      "source": [
        "!pip install youtube-dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLJAdFFw0r2h"
      },
      "source": [
        "get any video. We have selected the particular one as it shows views of a city life "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsy0lTrF9LeH"
      },
      "source": [
        "import pafy\n",
        "\n",
        "url = \"https://www.youtube.com/watch?v=_MMpKnfT5oU\"\n",
        "video = pafy.new(url)\n",
        "best = video.getbest(preftype=\"mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aYL1c2gzfcO"
      },
      "source": [
        "mount your Google Drive and get the following file (customize the path; the file is included in the git repo):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvt-ljHjz1gF"
      },
      "source": [
        "%cp /content/drive/MyDrive/object_detection/object_detection_functions.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt1r1WxTz3uX"
      },
      "source": [
        "from object_detection_functions import object_detection_analysis_with_nms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFu03CtN-iJn"
      },
      "source": [
        "**WARNING:** this will be a very slow loop in part due to the cv2_imshow() command. Everyframe processed will be displayed after the previous one. To break this loop go to Runtime->Interrupt Execution\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5zjbPZ7DSur"
      },
      "source": [
        "cap = cv2.VideoCapture(best.url)\n",
        "\n",
        "new_width = 640\n",
        "new_height = 480\n",
        "dim = (new_width, new_height)\n",
        "\n",
        "if cap.isOpened():\n",
        "  while True:\n",
        "    #get the current frame from video stream\n",
        "    ret,frame = cap.read()\n",
        "\n",
        "    frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(frame, scalefactor, new_size, swapRB=True, crop=False)\n",
        "\n",
        "    # input pre-processed blob into the model\n",
        "    yolo_model.setInput(blob)\n",
        "\n",
        "    # compute the forward pass for the input, storing the results per output layer in a list\n",
        "    obj_detections_in_layers = yolo_model.forward(output_layers)\n",
        "\n",
        "    # get  the object detections drawn on  the frame\n",
        "    frame, winner_boxes = object_detection_analysis_with_nms(frame, class_labels, class_colors, obj_detections_in_layers, score_threshold, nms_threshold)\n",
        "\n",
        "    #display the frame\n",
        "    cv2_imshow(frame)\n",
        "    # if running outside Colab notebooks use:\n",
        "    # cv2.imshow(frame)\n",
        "\n",
        "    #terminate while loop if 'q' key is pressed - applicable outside the notebooks\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "      break\n",
        "\n",
        "  #releasing the stream and the camera\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}