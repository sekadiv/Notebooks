{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this project, we are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Import libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, ZeroPadding3D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling3D, Conv3D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "rn.seed(30)\n",
    "tf.set_random_seed(30)\n",
    "\n",
    "train_path = './Project_data/train'\n",
    "val_path = './Project_data/val'\n",
    "train_doc = np.random.permutation(open('./Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('./Project_data/val.csv').readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Class\n",
    "This is one of the most important part of the code. The overall structure of the generator is broken down into modules. In the generator, we are going to preprocess the images as we have images of 2 different dimensions as well as create a batch of video frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, width=120, height=120, frames=30, channel=3, \n",
    "                 crop = True, normalize = False, affine = False, flip = False, edge = False  ):\n",
    "        self.width = width   # X dimension of the image\n",
    "        self.height = height # Y dimesnion of the image\n",
    "        self.frames = frames # length/depth of the video frames\n",
    "        self.channel = channel # number of channels in images 3 for color(RGB) and 1 for Gray  \n",
    "        self.affine = affine # augment data with affine transform of the image\n",
    "        self.flip = flip\n",
    "        self.normalize =  normalize\n",
    "        self.edge = edge # edge detection\n",
    "        self.crop = crop\n",
    "\n",
    "    # Helper function to generate a random affine transform on the image\n",
    "    def __get_random_affine(self): # private method\n",
    "        dx, dy = np.random.randint(-1.7, 1.8, 2)\n",
    "        M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "        return M\n",
    "\n",
    "    # Helper function to initialize all the batch image data and labels\n",
    "    def __init_batch_data(self, batch_size): # private method\n",
    "        batch_data = np.zeros((batch_size, self.frames, self.width, self.height, self.channel)) \n",
    "        batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "    def __load_batch_images(self, source_path, folder_list, batch_num, batch_size, t): # private method\n",
    "    \n",
    "        batch_data,batch_labels = self.__init_batch_data(batch_size)\n",
    "        # We will also build a agumented batch data\n",
    "        if self.affine:\n",
    "            batch_data_aug,batch_labels_aug = self.__init_batch_data(batch_size)\n",
    "        if self.flip:\n",
    "            batch_data_flip,batch_labels_flip = self.__init_batch_data(batch_size)\n",
    "\n",
    "        #create a list of image numbers you want to use for a particular video\n",
    "        img_idx = [x for x in range(0, self.frames)] \n",
    "\n",
    "        for folder in range(batch_size): # iterate over the batch_size\n",
    "            # read all the images in the folder\n",
    "            imgs = sorted(os.listdir(source_path+'/'+ t[folder + (batch_num*batch_size)].split(';')[0])) \n",
    "            # Generate a random affine to be used in image transformation for buidling agumented data set\n",
    "            M = self.__get_random_affine()\n",
    "            \n",
    "            #  Iterate over the frames/images of a folder to read them in\n",
    "            for idx, item in enumerate(img_idx): \n",
    "                image = cv2.imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                #and the conv3D will throw error if the inputs in a batch have different shapes  \n",
    "                if self.crop:\n",
    "                    image = self.__crop(image)\n",
    "                # If normalize is set normalize the image else use the raw image.\n",
    "                if self.normalize:\n",
    "                    resized = self.__normalize(self.__resize(image))\n",
    "                else:\n",
    "                    resized = self.__resize(image)\n",
    "                # If the input is edge detected image then use the sobelx, sobely and laplacian as 3 channel of the edge detected image\n",
    "                if self.edge:\n",
    "                    resized = self.__edge(resized)\n",
    "                \n",
    "                batch_data[folder,idx] = resized\n",
    "                if self.affine:\n",
    "                    batch_data_aug[folder,idx] = self.__affine(resized, M)   \n",
    "                if self.flip:\n",
    "                    batch_data_flip[folder,idx] = self.__flip(resized)   \n",
    "\n",
    "            batch_labels[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "            if self.affine:\n",
    "                batch_labels_aug[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "            if self.flip:\n",
    "                if int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==0:\n",
    "                    batch_labels_flip[folder, 1] = 1\n",
    "                elif int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==1:\n",
    "                    batch_labels_flip[folder, 0] = 1\n",
    "                else:\n",
    "                    batch_labels_flip[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        \n",
    "        if self.affine:\n",
    "            batch_data = np.append(batch_data, batch_data_aug, axis = 0) \n",
    "            batch_labels = np.append(batch_labels, batch_labels_aug, axis = 0) \n",
    "        if self.flip:\n",
    "            batch_data = np.append(batch_data, batch_data_flip, axis = 0) \n",
    "            batch_labels = np.append(batch_labels, batch_labels_flip, axis = 0) \n",
    "\n",
    "        return batch_data, batch_labels\n",
    "    \n",
    "    def generator(self, source_path, folder_list, batch_size): # public method\n",
    "        print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "            for batch in range(num_batches): # we iterate over the number of batches\n",
    "                # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "                yield self.__load_batch_images(source_path, folder_list, batch, batch_size, t) \n",
    "            \n",
    "            # Code for the remaining data points which are left after full batches\n",
    "            if (len(folder_list) != batch_size*num_batches):\n",
    "                batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "                yield self.__load_batch_images(source_path, folder_list, num_batches, batch_size, t)\n",
    "\n",
    "    # Helper function to perfom affice transform on the image\n",
    "    def __affine(self, image, M):\n",
    "        return cv2.warpAffine(image, M, (image.shape[0], image.shape[1]))\n",
    "\n",
    "    # Helper function to flip the image\n",
    "    def __flip(self, image):\n",
    "        return np.flip(image,1)\n",
    "    \n",
    "    # Helper function to normalise the data\n",
    "    def __normalize(self, image):\n",
    "        return image/127.5-1\n",
    "    \n",
    "    # Helper function to resize the image\n",
    "    def __resize(self, image):\n",
    "        return cv2.resize(image, (self.width,self.height), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Helper function to crop the image\n",
    "    def __crop(self, image):\n",
    "        if image.shape[0] != image.shape[1]:\n",
    "            return image[0:120, 20:140]\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    # Helper function for edge detection\n",
    "    def __edge(self, image):\n",
    "        edge = np.zeros((image.shape[0], image.shape[1], image.shape[2]))\n",
    "        edge[:,:,0] = cv2.Laplacian(cv2.GaussianBlur(image[:,:,0],(3,3),0),cv2.CV_64F)\n",
    "        edge[:,:,1] = cv2.Laplacian(cv2.GaussianBlur(image[:,:,1],(3,3),0),cv2.CV_64F)\n",
    "        edge[:,:,2] = cv2.Laplacian(cv2.GaussianBlur(image[:,:,2],(3,3),0),cv2.CV_64F)\n",
    "        return edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelGenerator(object):\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d1(cls, input_shape, nb_classes):\n",
    "        \"\"\"\n",
    "        Build a 3D convolutional network, based loosely on C3D.\n",
    "            https://arxiv.org/pdf/1412.0767.pdf\n",
    "        \"\"\"\n",
    "        # Model.\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(\n",
    "            8, (3,3,3), activation='relu', input_shape=input_shape\n",
    "        ))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "        model.add(Conv3D(16, (3,3,3), activation='relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "        model.add(Conv3D(32, (3,3,3), activation='relu'))\n",
    "        model.add(Conv3D(32, (3,3,3), activation='relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "        model.add(Conv3D(64, (2,2,2), activation='relu'))\n",
    "        model.add(Conv3D(64, (2,2,2), activation='relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(256))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d2(cls, input_shape, nb_classes):\n",
    "        \"\"\"\n",
    "        Build a 3D convolutional network, aka C3D.\n",
    "            https://arxiv.org/pdf/1412.0767.pdf\n",
    "        \"\"\"        \n",
    "        model = Sequential()\n",
    "        # 1st layer group\n",
    "        model.add(Conv3D(16, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv1',\n",
    "                         subsample=(1, 1, 1),\n",
    "                         input_shape=input_shape))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n",
    "                               border_mode='valid', name='pool1'))\n",
    "        # 2nd layer group\n",
    "        model.add(Conv3D(32, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv2',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               border_mode='valid', name='pool2'))\n",
    "        # 3rd layer group\n",
    "        model.add(Conv3D(64, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv3a',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(Conv3D(64, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv3b',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               border_mode='valid', name='pool3'))\n",
    "        # 4th layer group\n",
    "        model.add(Conv3D(128, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv4a',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(Conv3D(128, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv4b',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               border_mode='valid', name='pool4'))\n",
    "\n",
    "        # 5th layer group\n",
    "        model.add(Conv3D(256, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv5a',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(Conv3D(256, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv5b',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(ZeroPadding3D(padding=(0, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               padding='valid', name='pool5'))\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # FC layers group\n",
    "        model.add(Dense(512, activation='relu', name='fc6'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(512, activation='relu', name='fc7'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d3(cls, input_shape, nb_classes):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, kernel_size=(3, 3, 3), input_shape=input_shape, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv3D(16, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    " \n",
    "    @classmethod\n",
    "    def c3d4(cls, input_shape, nb_classes):\n",
    "        # Define model\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv3D(8, kernel_size=(3,3,3), input_shape=input_shape, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(16, kernel_size=(3,3,3), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(32, kernel_size=(1,3,3), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(64, kernel_size=(1,3,3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        #Flatten Layers\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        #softmax layer\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d5(cls, input_shape, nb_classes):\n",
    "        # Define model\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv3D(8, kernel_size=(3,3,3), input_shape=input_shape, padding='same'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(16, kernel_size=(3,3,3), padding='same'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(32, kernel_size=(1,3,3), padding='same'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(64, kernel_size=(1,3,3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        #Flatten Layers\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        #softmax layer\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        return model   \n",
    "    \n",
    "    @classmethod\n",
    "    def lstm(cls, input_shape, nb_classes):\n",
    "        \"\"\"Build a simple LSTM network. We pass the extracted features from\n",
    "        our CNN to this model predomenently.\"\"\"\n",
    "        # Model.\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(2048, return_sequences=False,\n",
    "                       input_shape=input_shape,\n",
    "                       dropout=0.5))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def lrcn(cls, input_shape, nb_classes):\n",
    "        \"\"\"Build a CNN into RNN.\n",
    "        Starting version from:\n",
    "            https://github.com/udacity/self-driving-car/blob/master/\n",
    "                steering-models/community-models/chauffeur/models.py\n",
    "        Heavily influenced by VGG-16:\n",
    "            https://arxiv.org/abs/1409.1556\n",
    "        Also known as an LRCN:\n",
    "            https://arxiv.org/pdf/1411.4389.pdf\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2),\n",
    "            activation='relu', padding='same'), input_shape=input_shape))\n",
    "        model.add(TimeDistributed(Conv2D(32, (3,3),\n",
    "            kernel_initializer=\"he_normal\", activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(128, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(128, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(256, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(256, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(512, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(512, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def mlp(cls, input_shape, nb_classes):\n",
    "        \"\"\"Build a simple MLP. It uses extracted features as the input\n",
    "        because of the otherwise too-high dimensionality.\"\"\"\n",
    "        # Model.\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=input_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(512))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size, num_epochs, model, train_generator, val_generator, optimiser=None):\n",
    "\n",
    "    curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "    num_train_sequences = len(train_doc)\n",
    "    print('# training sequences =', num_train_sequences)\n",
    "    num_val_sequences = len(val_doc)\n",
    "    print('# validation sequences =', num_val_sequences)\n",
    "    print('# batch size =', batch_size)    \n",
    "    print('# epochs =', num_epochs)\n",
    "\n",
    "    #optimizer = Adam(lr=rate) \n",
    "    #write your optimizer\n",
    "    if optimiser == None:\n",
    "        optimiser = Adam() \n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    print (model.summary())\n",
    "    \n",
    "    model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "    if not os.path.exists(model_name):\n",
    "        os.mkdir(model_name)\n",
    "            \n",
    "    filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath, \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=False, \n",
    "                                 save_weights_only=False, \n",
    "                                 mode='auto', \n",
    "                                 period=1)\n",
    "    LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "    callbacks_list = [checkpoint, LR]\n",
    "\n",
    "    if (num_train_sequences%batch_size) == 0:\n",
    "        steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "    else:\n",
    "        steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "    if (num_val_sequences%batch_size) == 0:\n",
    "        validation_steps = int(num_val_sequences/batch_size)\n",
    "    else:\n",
    "        validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "    model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                callbacks=callbacks_list, validation_data=val_generator, \n",
    "                validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "    \n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "def clear_cuda():\n",
    "    #cuda.select_device(0)\n",
    "    #cuda.close()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1a : Resize to 120*120,  Raw image input, No cropping, No normalisation, No agumentation, No flipped images, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 26s 762ms/step - loss: 12.8213 - categorical_accuracy: 0.2046 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_17_53.160408/model-00001-12.73929-0.20965-12.41093-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 4s 115ms/step - loss: 12.9577 - categorical_accuracy: 0.1961 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_17_53.160408/model-00002-12.95768-0.19608-12.41093-0.23000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 4s 110ms/step - loss: 12.9577 - categorical_accuracy: 0.1961 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_17_53.160408/model-00003-12.95768-0.19608-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 4s 105ms/step - loss: 13.1157 - categorical_accuracy: 0.1863 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_17_53.160408/model-00004-13.11570-0.18627-12.41093-0.23000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 4s 113ms/step - loss: 12.7997 - categorical_accuracy: 0.2059 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_17_53.160408/model-00005-12.79966-0.20588-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 4s 118ms/step - loss: 12.9577 - categorical_accuracy: 0.1961 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_17_53.160408/model-00006-12.95768-0.19608-12.41093-0.23000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 3s 102ms/step - loss: 12.7997 - categorical_accuracy: 0.2059 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_17_53.160408/model-00007-12.79966-0.20588-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 4s 122ms/step - loss: 11.5355 - categorical_accuracy: 0.2843 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_17_53.160408/model-00008-11.53550-0.28431-12.41093-0.23000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 4s 122ms/step - loss: 12.4836 - categorical_accuracy: 0.2255 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_17_53.160408/model-00009-12.48362-0.22549-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 12.6416 - categorical_accuracy: 0.2157 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_17_53.160408/model-00010-12.64164-0.21569-12.41093-0.23000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 5s 138ms/step - loss: 13.1157 - categorical_accuracy: 0.1863 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_17_53.160408/model-00011-13.11571-0.18627-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 5s 136ms/step - loss: 12.7997 - categorical_accuracy: 0.2059 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_17_53.160408/model-00012-12.79966-0.20588-12.41093-0.23000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 5s 139ms/step - loss: 13.1157 - categorical_accuracy: 0.1863 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_17_53.160408/model-00013-13.11570-0.18627-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 5s 138ms/step - loss: 13.4317 - categorical_accuracy: 0.1667 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_17_53.160408/model-00014-13.43175-0.16667-12.41093-0.23000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 12.0096 - categorical_accuracy: 0.2549 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_17_53.160408/model-00015-12.00956-0.25490-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 5s 137ms/step - loss: 12.7997 - categorical_accuracy: 0.2059 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_17_53.160408/model-00016-12.79966-0.20588-12.41093-0.23000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 5s 142ms/step - loss: 11.5355 - categorical_accuracy: 0.2843 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_17_53.160408/model-00017-11.53550-0.28431-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 136ms/step - loss: 14.5379 - categorical_accuracy: 0.0980 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_17_53.160408/model-00018-14.53789-0.09804-12.41093-0.23000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 5s 138ms/step - loss: 12.6416 - categorical_accuracy: 0.2157 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_17_53.160408/model-00019-12.64164-0.21569-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 5s 136ms/step - loss: 12.1676 - categorical_accuracy: 0.2451 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_17_53.160408/model-00020-12.16758-0.24510-12.41093-0.23000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator()\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1b : Resize to 120*120, agumentation, No flipped images, No cropping, No normalisation, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 31s 919ms/step - loss: 13.0202 - categorical_accuracy: 0.1917 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_19_44.687027/model-00001-13.00995-0.19231-13.53920-0.16000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 5s 140ms/step - loss: 13.2737 - categorical_accuracy: 0.1765 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_19_44.687027/model-00002-13.27373-0.17647-13.53920-0.16000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 173ms/step - loss: 13.7478 - categorical_accuracy: 0.1471 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_19_44.687027/model-00003-13.74779-0.14706-13.53920-0.16000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 13.9848 - categorical_accuracy: 0.1324 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_19_44.687027/model-00004-13.98482-0.13235-13.53920-0.16000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 13.6688 - categorical_accuracy: 0.1520 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_19_44.687027/model-00005-13.66878-0.15196-13.53920-0.16000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 13.1157 - categorical_accuracy: 0.1863 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_19_44.687027/model-00006-13.11571-0.18627-13.53920-0.16000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 12.2466 - categorical_accuracy: 0.2402 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_19_44.687027/model-00007-12.24659-0.24020-13.53920-0.16000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 12.4046 - categorical_accuracy: 0.2304 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_19_44.687027/model-00008-12.40461-0.23039-13.53920-0.16000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 13.5108 - categorical_accuracy: 0.1618 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_19_44.687027/model-00009-13.51076-0.16176-13.53920-0.16000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 12.4836 - categorical_accuracy: 0.2255 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_19_44.687027/model-00010-12.48362-0.22549-13.53920-0.16000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 13.7478 - categorical_accuracy: 0.1471 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_19_44.687027/model-00011-13.74779-0.14706-13.53920-0.16000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 5s 137ms/step - loss: 13.5108 - categorical_accuracy: 0.1618 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_19_44.687027/model-00012-13.51076-0.16176-13.53920-0.16000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 12.4046 - categorical_accuracy: 0.2304 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_19_44.687027/model-00013-12.40461-0.23039-13.53920-0.16000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 13.1157 - categorical_accuracy: 0.1863 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_19_44.687027/model-00014-13.11571-0.18627-13.53920-0.16000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 12.7997 - categorical_accuracy: 0.2059 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_19_44.687027/model-00015-12.79966-0.20588-13.53920-0.16000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 13.4317 - categorical_accuracy: 0.1667 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_19_44.687027/model-00016-13.43175-0.16667-13.53920-0.16000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 13.0367 - categorical_accuracy: 0.1912 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_19_44.687027/model-00017-13.03669-0.19118-13.53920-0.16000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 159ms/step - loss: 13.5898 - categorical_accuracy: 0.1569 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_19_44.687027/model-00018-13.58977-0.15686-13.53920-0.16000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 12.7997 - categorical_accuracy: 0.2059 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_19_44.687027/model-00019-12.79966-0.20588-13.53920-0.16000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 6s 179ms/step - loss: 13.3527 - categorical_accuracy: 0.1716 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_19_44.687027/model-00020-13.35274-0.17157-13.53920-0.16000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1c : Resize to 120*120, agumentation, flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 37s 1s/step - loss: 12.8788 - categorical_accuracy: 0.2004 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_21_58.844546/model-00001-12.93189-0.19708-12.57211-0.22000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 12.4836 - categorical_accuracy: 0.2255 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_21_58.844546/model-00002-12.48362-0.22549-12.57211-0.22000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 175ms/step - loss: 11.6935 - categorical_accuracy: 0.2745 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_21_58.844546/model-00003-11.69352-0.27451-12.57211-0.22000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 6s 181ms/step - loss: 13.4317 - categorical_accuracy: 0.1667 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_21_58.844546/model-00004-13.43175-0.16667-12.57211-0.22000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 6s 179ms/step - loss: 13.4317 - categorical_accuracy: 0.1667 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_21_58.844546/model-00005-13.43175-0.16667-12.57211-0.22000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 6s 164ms/step - loss: 13.9058 - categorical_accuracy: 0.1373 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_21_58.844546/model-00006-13.90581-0.13725-12.57211-0.22000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 6s 178ms/step - loss: 13.1157 - categorical_accuracy: 0.1863 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_21_58.844546/model-00007-13.11570-0.18627-12.57211-0.22000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 6s 183ms/step - loss: 13.2211 - categorical_accuracy: 0.1797 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_21_58.844546/model-00008-13.22105-0.17974-12.57211-0.22000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 6s 189ms/step - loss: 12.4836 - categorical_accuracy: 0.2255 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_21_58.844546/model-00009-12.48362-0.22549-12.57211-0.22000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 5s 143ms/step - loss: 12.7997 - categorical_accuracy: 0.2059 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_21_58.844546/model-00010-12.79966-0.20588-12.57211-0.22000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 5s 140ms/step - loss: 13.2737 - categorical_accuracy: 0.1765 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_21_58.844546/model-00011-13.27373-0.17647-12.57211-0.22000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 6s 172ms/step - loss: 12.9577 - categorical_accuracy: 0.1961 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_21_58.844546/model-00012-12.95768-0.19608-12.57211-0.22000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 6s 175ms/step - loss: 12.4309 - categorical_accuracy: 0.2288 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_21_58.844546/model-00013-12.43095-0.22876-12.57211-0.22000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 6s 180ms/step - loss: 13.1157 - categorical_accuracy: 0.1863 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_21_58.844546/model-00014-13.11570-0.18627-12.57211-0.22000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 5s 156ms/step - loss: 13.5898 - categorical_accuracy: 0.1569 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_21_58.844546/model-00015-13.58977-0.15686-12.57211-0.22000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 6s 190ms/step - loss: 12.0096 - categorical_accuracy: 0.2549 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_21_58.844546/model-00016-12.00956-0.25490-12.57211-0.22000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 6s 178ms/step - loss: 12.4836 - categorical_accuracy: 0.2255 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_21_58.844546/model-00017-12.48362-0.22549-12.57211-0.22000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 6s 168ms/step - loss: 12.7997 - categorical_accuracy: 0.2059 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_21_58.844546/model-00018-12.79966-0.20588-12.57211-0.22000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 6s 185ms/step - loss: 13.4317 - categorical_accuracy: 0.1667 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_21_58.844546/model-00019-13.43175-0.16667-12.57211-0.22000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 6s 165ms/step - loss: 12.7997 - categorical_accuracy: 0.2059 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_21_58.844546/model-00020-12.79966-0.20588-12.57211-0.22000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1d : Resize to 120*120,  agumentation, flipped images, normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 39s 1s/step - loss: 1.7442 - categorical_accuracy: 0.2198 - val_loss: 12.0548 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_24_30.405740/model-00001-1.74767-0.22524-12.05480-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 6s 184ms/step - loss: 1.5880 - categorical_accuracy: 0.2124 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_24_30.405740/model-00002-1.58803-0.21242-12.57211-0.22000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 186ms/step - loss: 1.5356 - categorical_accuracy: 0.2908 - val_loss: 11.4677 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_24_30.405740/model-00003-1.53557-0.29085-11.46772-0.23000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 6s 189ms/step - loss: 1.6427 - categorical_accuracy: 0.2222 - val_loss: 10.6737 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_24_30.405740/model-00004-1.64266-0.22222-10.67373-0.23000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 7s 197ms/step - loss: 1.6390 - categorical_accuracy: 0.1242 - val_loss: 9.3224 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_24_30.405740/model-00005-1.63904-0.12418-9.32243-0.24000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 6s 179ms/step - loss: 1.6307 - categorical_accuracy: 0.1765 - val_loss: 9.6737 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_24_30.405740/model-00006-1.63074-0.17647-9.67374-0.23000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 1.6149 - categorical_accuracy: 0.2026 - val_loss: 11.5835 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_24_30.405740/model-00007-1.61489-0.20261-11.58353-0.23000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 6s 184ms/step - loss: 1.5933 - categorical_accuracy: 0.3301 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_24_30.405740/model-00008-1.59325-0.33007-12.41093-0.23000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 7s 196ms/step - loss: 1.4548 - categorical_accuracy: 0.4085 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_24_30.405740/model-00009-1.45480-0.40850-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 6s 164ms/step - loss: 1.2635 - categorical_accuracy: 0.3954 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_24_30.405740/model-00010-1.26352-0.39542-12.41093-0.23000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.2204 - categorical_accuracy: 0.4510 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_24_30.405740/model-00011-1.22038-0.45098-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 7s 207ms/step - loss: 1.1795 - categorical_accuracy: 0.4444 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_24_30.405740/model-00012-1.17950-0.44444-12.41093-0.23000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 6s 181ms/step - loss: 1.2239 - categorical_accuracy: 0.4085 - val_loss: 11.8406 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_24_30.405740/model-00013-1.22386-0.40850-11.84062-0.26000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 6s 177ms/step - loss: 1.2276 - categorical_accuracy: 0.4542 - val_loss: 12.0886 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_24_30.405740/model-00014-1.22756-0.45425-12.08857-0.25000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 6s 189ms/step - loss: 1.1856 - categorical_accuracy: 0.4771 - val_loss: 11.6050 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_24_30.405740/model-00015-1.18559-0.47712-11.60503-0.28000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 1.1229 - categorical_accuracy: 0.4739 - val_loss: 11.6050 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_24_30.405740/model-00016-1.12293-0.47386-11.60503-0.28000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 6s 186ms/step - loss: 1.0783 - categorical_accuracy: 0.5392 - val_loss: 11.9274 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_24_30.405740/model-00017-1.07835-0.53922-11.92739-0.26000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 6s 188ms/step - loss: 1.1344 - categorical_accuracy: 0.5261 - val_loss: 11.9088 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_24_30.405740/model-00018-1.13436-0.52614-11.90885-0.26000.h5\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 6s 181ms/step - loss: 1.1060 - categorical_accuracy: 0.4804 - val_loss: 12.0886 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_24_30.405740/model-00019-1.10598-0.48039-12.08857-0.25000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 6s 182ms/step - loss: 1.0769 - categorical_accuracy: 0.5229 - val_loss: 12.0886 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_24_30.405740/model-00020-1.07690-0.52288-12.08857-0.25000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1e : Resize to 120*120,  agumentation, flipped images, normalisation, cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 40s 1s/step - loss: 1.7331 - categorical_accuracy: 0.2205 - val_loss: 12.3378 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_27_14.268054/model-00001-1.74043-0.22323-12.33778-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 6s 183ms/step - loss: 1.5517 - categorical_accuracy: 0.3072 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_27_14.268054/model-00002-1.55169-0.30719-12.41093-0.23000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 178ms/step - loss: 1.6571 - categorical_accuracy: 0.1765 - val_loss: 11.2436 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_27_14.268054/model-00003-1.65714-0.17647-11.24361-0.24000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 6s 182ms/step - loss: 1.6184 - categorical_accuracy: 0.1765 - val_loss: 11.1183 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_27_14.268054/model-00004-1.61836-0.17647-11.11832-0.26000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 7s 206ms/step - loss: 1.6157 - categorical_accuracy: 0.1961 - val_loss: 11.1666 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_27_14.268054/model-00005-1.61573-0.19608-11.16660-0.23000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 7s 211ms/step - loss: 1.6203 - categorical_accuracy: 0.1634 - val_loss: 11.1758 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_27_14.268054/model-00006-1.62033-0.16340-11.17583-0.24000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 7s 191ms/step - loss: 1.6150 - categorical_accuracy: 0.1928 - val_loss: 11.4916 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_27_14.268054/model-00007-1.61502-0.19281-11.49160-0.22000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 1.6206 - categorical_accuracy: 0.1765 - val_loss: 11.4358 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_27_14.268054/model-00008-1.62063-0.17647-11.43583-0.22000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.6136 - categorical_accuracy: 0.2124 - val_loss: 11.2736 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_27_14.268054/model-00009-1.61364-0.21242-11.27357-0.23000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 1.6045 - categorical_accuracy: 0.2124 - val_loss: 11.2576 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_27_14.268054/model-00010-1.60449-0.21242-11.25761-0.23000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 6s 187ms/step - loss: 1.6120 - categorical_accuracy: 0.1993 - val_loss: 11.3519 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_27_14.268054/model-00011-1.61196-0.19935-11.35191-0.22000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 6s 188ms/step - loss: 1.6021 - categorical_accuracy: 0.2516 - val_loss: 11.4623 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_27_14.268054/model-00012-1.60209-0.25163-11.46227-0.22000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 1.6083 - categorical_accuracy: 0.2418 - val_loss: 11.4505 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_27_14.268054/model-00013-1.60830-0.24183-11.45048-0.22000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 1.6194 - categorical_accuracy: 0.1373 - val_loss: 11.4397 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_27_14.268054/model-00014-1.61939-0.13725-11.43970-0.22000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 7s 206ms/step - loss: 1.6137 - categorical_accuracy: 0.1667 - val_loss: 11.4535 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_27_14.268054/model-00015-1.61369-0.16667-11.45353-0.22000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 1.6103 - categorical_accuracy: 0.1667 - val_loss: 11.4629 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_27_14.268054/model-00016-1.61032-0.16667-11.46293-0.22000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 6s 190ms/step - loss: 1.6115 - categorical_accuracy: 0.2124 - val_loss: 11.4629 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_27_14.268054/model-00017-1.61154-0.21242-11.46287-0.22000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 6s 190ms/step - loss: 1.5983 - categorical_accuracy: 0.2451 - val_loss: 11.4675 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_27_14.268054/model-00018-1.59826-0.24510-11.46753-0.22000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 7s 200ms/step - loss: 1.6111 - categorical_accuracy: 0.1928 - val_loss: 11.4666 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_27_14.268054/model-00019-1.61114-0.19281-11.46664-0.22000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 6s 186ms/step - loss: 1.6066 - categorical_accuracy: 0.1961 - val_loss: 11.4659 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_27_14.268054/model-00020-1.60659-0.19608-11.46594-0.22000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1f : Resize to 120*120,  agumentation, flipped images, normalisation, cropping, edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 45s 1s/step - loss: 1.6431 - categorical_accuracy: 0.2217 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_30_03.823329/model-00001-1.64619-0.22725-12.57211-0.22000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 1.5410 - categorical_accuracy: 0.2843 - val_loss: 11.8811 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_30_03.823329/model-00002-1.54099-0.28431-11.88110-0.24000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 7s 209ms/step - loss: 1.6156 - categorical_accuracy: 0.1863 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_30_03.823329/model-00003-1.61563-0.18627-12.57211-0.22000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.5456 - categorical_accuracy: 0.2320 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_30_03.823329/model-00004-1.54556-0.23203-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 1.3928 - categorical_accuracy: 0.4020 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_30_03.823329/model-00005-1.39285-0.40196-12.24975-0.24000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 8s 221ms/step - loss: 1.3561 - categorical_accuracy: 0.4248 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_30_03.823329/model-00006-1.35607-0.42484-12.24975-0.24000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 7s 214ms/step - loss: 1.2937 - categorical_accuracy: 0.4183 - val_loss: 11.3834 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_30_03.823329/model-00007-1.29371-0.41830-11.38340-0.28000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 7s 218ms/step - loss: 1.4249 - categorical_accuracy: 0.3627 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_30_03.823329/model-00008-1.42494-0.36275-12.24975-0.24000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 7s 216ms/step - loss: 1.2871 - categorical_accuracy: 0.4248 - val_loss: 11.2827 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_30_03.823329/model-00009-1.28715-0.42484-11.28267-0.30000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.1282 - categorical_accuracy: 0.5098 - val_loss: 11.2827 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_30_03.823329/model-00010-1.12815-0.50980-11.28267-0.30000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 7s 217ms/step - loss: 1.2406 - categorical_accuracy: 0.4739 - val_loss: 11.9274 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_30_03.823329/model-00011-1.24063-0.47386-11.92739-0.26000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 7s 216ms/step - loss: 1.1081 - categorical_accuracy: 0.5425 - val_loss: 11.9274 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_30_03.823329/model-00012-1.10813-0.54248-11.92739-0.26000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 8s 222ms/step - loss: 1.1064 - categorical_accuracy: 0.5425 - val_loss: 11.2827 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_30_03.823329/model-00013-1.10638-0.54248-11.28267-0.30000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.0275 - categorical_accuracy: 0.5490 - val_loss: 11.2827 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_30_03.823329/model-00014-1.02754-0.54902-11.28267-0.30000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 7s 209ms/step - loss: 1.0274 - categorical_accuracy: 0.5719 - val_loss: 11.2827 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_30_03.823329/model-00015-1.02739-0.57190-11.28267-0.30000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 7s 214ms/step - loss: 1.0453 - categorical_accuracy: 0.5556 - val_loss: 11.1457 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_30_03.823329/model-00016-1.04525-0.55556-11.14572-0.30000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 0.9928 - categorical_accuracy: 0.6405 - val_loss: 11.2827 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_30_03.823329/model-00017-0.99281-0.64052-11.28267-0.30000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 7s 215ms/step - loss: 0.9497 - categorical_accuracy: 0.6111 - val_loss: 11.2827 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_30_03.823329/model-00018-0.94970-0.61111-11.28267-0.30000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 7s 204ms/step - loss: 1.0505 - categorical_accuracy: 0.5458 - val_loss: 11.1215 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_30_03.823329/model-00019-1.05052-0.54575-11.12149-0.31000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 7s 211ms/step - loss: 0.9034 - categorical_accuracy: 0.6111 - val_loss: 11.1215 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_30_03.823329/model-00020-0.90338-0.61111-11.12149-0.31000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2a : Resize to 120*120,  No agumentation, No flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(16, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv1\", input_shape=(30, 120, ..., strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv2\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5b\", strides=(1, 1, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 30, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 30, 60, 60, 32)    13856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 15, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 15, 30, 30, 64)    55360     \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 15, 30, 30, 64)    110656    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 7, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 7, 15, 15, 128)    221312    \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 7, 15, 15, 128)    442496    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 3, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 3, 7, 7, 256)      884992    \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 3, 7, 7, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPaddin (None, 3, 9, 9, 256)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 5,862,597\n",
      "Trainable params: 5,862,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path = Source path =  ./Project_data/train ; batch size = 20\n",
      " ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 26s 766ms/step - loss: 2.0443 - categorical_accuracy: 0.1884 - val_loss: 1.6083 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_33_08.395073/model-00001-2.05525-0.19306-1.60826-0.18000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 1.6249 - categorical_accuracy: 0.2255 - val_loss: 1.6054 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_33_08.395073/model-00002-1.62487-0.22549-1.60542-0.21000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 3s 100ms/step - loss: 1.6158 - categorical_accuracy: 0.2059 - val_loss: 1.6084 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_33_08.395073/model-00003-1.61582-0.20588-1.60841-0.21000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 4s 126ms/step - loss: 1.6089 - categorical_accuracy: 0.2549 - val_loss: 1.6108 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_33_08.395073/model-00004-1.60890-0.25490-1.61075-0.21000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 4s 126ms/step - loss: 1.6128 - categorical_accuracy: 0.1667 - val_loss: 1.6098 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_33_08.395073/model-00005-1.61276-0.16667-1.60981-0.21000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 4s 119ms/step - loss: 1.6138 - categorical_accuracy: 0.1961 - val_loss: 1.6087 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_33_08.395073/model-00006-1.61381-0.19608-1.60873-0.21000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 4s 114ms/step - loss: 1.6101 - categorical_accuracy: 0.1667 - val_loss: 1.6081 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_33_08.395073/model-00007-1.61006-0.16667-1.60808-0.21000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 3s 100ms/step - loss: 1.6122 - categorical_accuracy: 0.2059 - val_loss: 1.6079 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_33_08.395073/model-00008-1.61219-0.20588-1.60790-0.21000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 1.6082 - categorical_accuracy: 0.2451 - val_loss: 1.6079 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_33_08.395073/model-00009-1.60817-0.24510-1.60786-0.21000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 5s 141ms/step - loss: 1.6042 - categorical_accuracy: 0.2157 - val_loss: 1.6076 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_33_08.395073/model-00010-1.60416-0.21569-1.60765-0.21000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 5s 136ms/step - loss: 1.6099 - categorical_accuracy: 0.1569 - val_loss: 1.6075 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_33_08.395073/model-00011-1.60992-0.15686-1.60752-0.21000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 5s 143ms/step - loss: 1.6071 - categorical_accuracy: 0.2353 - val_loss: 1.6074 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_33_08.395073/model-00012-1.60710-0.23529-1.60739-0.21000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 5s 137ms/step - loss: 1.6082 - categorical_accuracy: 0.1471 - val_loss: 1.6075 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_33_08.395073/model-00013-1.60817-0.14706-1.60751-0.21000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 5s 137ms/step - loss: 1.6158 - categorical_accuracy: 0.1765 - val_loss: 1.6076 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_33_08.395073/model-00014-1.61582-0.17647-1.60760-0.21000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 1.6121 - categorical_accuracy: 0.1569 - val_loss: 1.6077 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_33_08.395073/model-00015-1.61206-0.15686-1.60766-0.21000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 5s 136ms/step - loss: 1.6101 - categorical_accuracy: 0.2255 - val_loss: 1.6077 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_33_08.395073/model-00016-1.61007-0.22549-1.60771-0.21000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 142ms/step - loss: 1.6099 - categorical_accuracy: 0.2451 - val_loss: 1.6077 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_33_08.395073/model-00017-1.60990-0.24510-1.60772-0.21000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 5s 138ms/step - loss: 1.6096 - categorical_accuracy: 0.1471 - val_loss: 1.6077 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_33_08.395073/model-00018-1.60957-0.14706-1.60770-0.21000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 5s 138ms/step - loss: 1.6048 - categorical_accuracy: 0.2647 - val_loss: 1.6077 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_33_08.395073/model-00019-1.60482-0.26471-1.60769-0.21000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 5s 135ms/step - loss: 1.6068 - categorical_accuracy: 0.2059 - val_loss: 1.6077 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_33_08.395073/model-00020-1.60683-0.20588-1.60769-0.21000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator()\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d2(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2b : Resize to 120*120, agumentation, No flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(16, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv1\", input_shape=(30, 120, ..., strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv2\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5b\", strides=(1, 1, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 30, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 30, 60, 60, 32)    13856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 15, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 15, 30, 30, 64)    55360     \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 15, 30, 30, 64)    110656    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 7, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 7, 15, 15, 128)    221312    \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 7, 15, 15, 128)    442496    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 3, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 3, 7, 7, 256)      884992    \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 3, 7, 7, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPaddin (None, 3, 9, 9, 256)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 5,862,597\n",
      "Trainable params: 5,862,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 32s 941ms/step - loss: 2.3590 - categorical_accuracy: 0.1917 - val_loss: 1.6080 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_35_00.467614/model-00001-2.37770-0.18401-1.60805-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 4s 126ms/step - loss: 1.6176 - categorical_accuracy: 0.1422 - val_loss: 1.6076 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_35_00.467614/model-00002-1.61757-0.14216-1.60761-0.23000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 162ms/step - loss: 1.6086 - categorical_accuracy: 0.2255 - val_loss: 1.6067 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_35_00.467614/model-00003-1.60864-0.22549-1.60671-0.23000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 6s 174ms/step - loss: 1.6133 - categorical_accuracy: 0.1863 - val_loss: 1.6078 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_35_00.467614/model-00004-1.61329-0.18627-1.60781-0.21000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 6s 177ms/step - loss: 1.6112 - categorical_accuracy: 0.1863 - val_loss: 1.6085 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_35_00.467614/model-00005-1.61117-0.18627-1.60847-0.18000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 6s 178ms/step - loss: 1.6137 - categorical_accuracy: 0.1471 - val_loss: 1.6075 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_35_00.467614/model-00006-1.61370-0.14706-1.60754-0.23000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 6s 166ms/step - loss: 1.6106 - categorical_accuracy: 0.2010 - val_loss: 1.6082 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_35_00.467614/model-00007-1.61064-0.20098-1.60823-0.18000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 5s 136ms/step - loss: 1.6082 - categorical_accuracy: 0.2059 - val_loss: 1.6085 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_35_00.467614/model-00008-1.60823-0.20588-1.60846-0.18000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 5s 162ms/step - loss: 1.6142 - categorical_accuracy: 0.1520 - val_loss: 1.6093 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_35_00.467614/model-00009-1.61425-0.15196-1.60928-0.18000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 6s 165ms/step - loss: 1.6101 - categorical_accuracy: 0.2353 - val_loss: 1.6094 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_35_00.467614/model-00010-1.61014-0.23529-1.60941-0.18000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 1.6089 - categorical_accuracy: 0.1863 - val_loss: 1.6094 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_35_00.467614/model-00011-1.60894-0.18627-1.60939-0.18000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 6s 162ms/step - loss: 1.6101 - categorical_accuracy: 0.2108 - val_loss: 1.6092 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_35_00.467614/model-00012-1.61011-0.21078-1.60916-0.18000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 6s 165ms/step - loss: 1.6096 - categorical_accuracy: 0.1912 - val_loss: 1.6090 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_35_00.467614/model-00013-1.60957-0.19118-1.60900-0.18000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 6s 164ms/step - loss: 1.6038 - categorical_accuracy: 0.2598 - val_loss: 1.6090 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_35_00.467614/model-00014-1.60383-0.25980-1.60896-0.18000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 1.6110 - categorical_accuracy: 0.1716 - val_loss: 1.6090 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_35_00.467614/model-00015-1.61097-0.17157-1.60898-0.18000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 6s 164ms/step - loss: 1.6049 - categorical_accuracy: 0.2500 - val_loss: 1.6090 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_35_00.467614/model-00016-1.60486-0.25000-1.60897-0.18000.h5\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 148ms/step - loss: 1.6102 - categorical_accuracy: 0.2304 - val_loss: 1.6090 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_35_00.467614/model-00017-1.61025-0.23039-1.60901-0.18000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 1.6091 - categorical_accuracy: 0.2108 - val_loss: 1.6090 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_35_00.467614/model-00018-1.60907-0.21078-1.60898-0.18000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 1.6101 - categorical_accuracy: 0.1471 - val_loss: 1.6090 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_35_00.467614/model-00019-1.61014-0.14706-1.60897-0.18000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 6s 163ms/step - loss: 1.6105 - categorical_accuracy: 0.2010 - val_loss: 1.6090 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_35_00.467614/model-00020-1.61051-0.20098-1.60896-0.18000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d2(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2c : Resize to 120*120, agumentation, flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(16, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv1\", input_shape=(30, 120, ..., strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv2\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5b\", strides=(1, 1, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 30, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 30, 60, 60, 32)    13856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 15, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 15, 30, 30, 64)    55360     \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 15, 30, 30, 64)    110656    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 7, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 7, 15, 15, 128)    221312    \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 7, 15, 15, 128)    442496    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 3, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 3, 7, 7, 256)      884992    \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 3, 7, 7, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPaddin (None, 3, 9, 9, 256)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 5,862,597\n",
      "Trainable params: 5,862,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = Source path =  ./Project_data/train ; batch size = 20\n",
      "20\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.9773 - categorical_accuracy: 0.2279 - val_loss: 1.5796 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_37_18.707246/model-00001-1.98694-0.22524-1.57960-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 1.6277 - categorical_accuracy: 0.1732 - val_loss: 1.6101 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_37_18.707246/model-00002-1.62769-0.17320-1.61008-0.21000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 181ms/step - loss: 1.6102 - categorical_accuracy: 0.1765 - val_loss: 1.6107 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_37_18.707246/model-00003-1.61023-0.17647-1.61069-0.22000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 6s 177ms/step - loss: 1.6114 - categorical_accuracy: 0.1863 - val_loss: 1.6103 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_37_18.707246/model-00004-1.61143-0.18627-1.61027-0.22000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 6s 186ms/step - loss: 1.6046 - categorical_accuracy: 0.2418 - val_loss: 1.6092 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_37_18.707246/model-00005-1.60455-0.24183-1.60918-0.22000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 6s 181ms/step - loss: 1.6163 - categorical_accuracy: 0.1569 - val_loss: 1.6086 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_37_18.707246/model-00006-1.61634-0.15686-1.60861-0.22000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 6s 180ms/step - loss: 1.6127 - categorical_accuracy: 0.1765 - val_loss: 1.6082 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_37_18.707246/model-00007-1.61273-0.17647-1.60817-0.21000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 6s 180ms/step - loss: 1.6163 - categorical_accuracy: 0.1503 - val_loss: 1.6083 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_37_18.707246/model-00008-1.61626-0.15033-1.60833-0.21000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 6s 176ms/step - loss: 1.6098 - categorical_accuracy: 0.1895 - val_loss: 1.6081 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_37_18.707246/model-00009-1.60981-0.18954-1.60807-0.21000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 6s 165ms/step - loss: 1.6070 - categorical_accuracy: 0.1797 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_37_18.707246/model-00010-1.60702-0.17974-1.60796-0.21000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 6s 187ms/step - loss: 1.6099 - categorical_accuracy: 0.1993 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_37_18.707246/model-00011-1.60991-0.19935-1.60797-0.21000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 6s 184ms/step - loss: 1.6089 - categorical_accuracy: 0.2092 - val_loss: 1.6079 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_37_18.707246/model-00012-1.60894-0.20915-1.60793-0.21000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 6s 187ms/step - loss: 1.6089 - categorical_accuracy: 0.2582 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_37_18.707246/model-00013-1.60887-0.25817-1.60800-0.21000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 6s 183ms/step - loss: 1.6100 - categorical_accuracy: 0.1863 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_37_18.707246/model-00014-1.61004-0.18627-1.60799-0.21000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 6s 162ms/step - loss: 1.6090 - categorical_accuracy: 0.2222 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_37_18.707246/model-00015-1.60902-0.22222-1.60798-0.21000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 1.6071 - categorical_accuracy: 0.2059 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_37_18.707246/model-00016-1.60714-0.20588-1.60797-0.21000.h5\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 6s 187ms/step - loss: 1.6071 - categorical_accuracy: 0.1993 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_37_18.707246/model-00017-1.60712-0.19935-1.60795-0.21000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 6s 189ms/step - loss: 1.6108 - categorical_accuracy: 0.2124 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_37_18.707246/model-00018-1.61079-0.21242-1.60795-0.21000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 6s 178ms/step - loss: 1.6079 - categorical_accuracy: 0.2353 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_37_18.707246/model-00019-1.60786-0.23529-1.60796-0.21000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 1.6123 - categorical_accuracy: 0.1830 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_37_18.707246/model-00020-1.61230-0.18301-1.60796-0.21000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d2(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2d : Resize to 120*120, agumentation, flipped images, normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(16, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv1\", input_shape=(30, 120, ..., strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv2\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5b\", strides=(1, 1, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 30, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 30, 60, 60, 32)    13856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 15, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 15, 30, 30, 64)    55360     \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 15, 30, 30, 64)    110656    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 7, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 7, 15, 15, 128)    221312    \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 7, 15, 15, 128)    442496    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 3, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 3, 7, 7, 256)      884992    \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 3, 7, 7, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPaddin (None, 3, 9, 9, 256)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 5,862,597\n",
      "Trainable params: 5,862,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 40s 1s/step - loss: 1.6162 - categorical_accuracy: 0.1955 - val_loss: 1.6139 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_39_56.119221/model-00001-1.61632-0.19759-1.61393-0.21000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 6s 164ms/step - loss: 1.6139 - categorical_accuracy: 0.1830 - val_loss: 1.6091 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_39_56.119221/model-00002-1.61389-0.18301-1.60914-0.18000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 1.6154 - categorical_accuracy: 0.1699 - val_loss: 1.6117 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_39_56.119221/model-00003-1.61544-0.16993-1.61175-0.22000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 1.6131 - categorical_accuracy: 0.1732 - val_loss: 1.6086 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_39_56.119221/model-00004-1.61311-0.17320-1.60860-0.21000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 6s 177ms/step - loss: 1.6164 - categorical_accuracy: 0.1111 - val_loss: 1.6070 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_39_56.119221/model-00005-1.61636-0.11111-1.60704-0.21000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 6s 190ms/step - loss: 1.6060 - categorical_accuracy: 0.2059 - val_loss: 1.6055 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_39_56.119221/model-00006-1.60597-0.20588-1.60553-0.23000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 7s 191ms/step - loss: 1.6145 - categorical_accuracy: 0.1732 - val_loss: 1.6072 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_39_56.119221/model-00007-1.61452-0.17320-1.60719-0.21000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 6s 191ms/step - loss: 1.6100 - categorical_accuracy: 0.1961 - val_loss: 1.6072 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_39_56.119221/model-00008-1.60999-0.19608-1.60716-0.21000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 6s 176ms/step - loss: 1.6102 - categorical_accuracy: 0.2190 - val_loss: 1.6072 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_39_56.119221/model-00009-1.61024-0.21895-1.60721-0.21000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.6055 - categorical_accuracy: 0.2386 - val_loss: 1.6073 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_39_56.119221/model-00010-1.60550-0.23856-1.60725-0.21000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 6s 185ms/step - loss: 1.6130 - categorical_accuracy: 0.1536 - val_loss: 1.6073 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_39_56.119221/model-00011-1.61302-0.15359-1.60728-0.21000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 6s 189ms/step - loss: 1.6073 - categorical_accuracy: 0.1830 - val_loss: 1.6070 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_39_56.119221/model-00012-1.60731-0.18301-1.60703-0.21000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 6s 186ms/step - loss: 1.6145 - categorical_accuracy: 0.1863 - val_loss: 1.6071 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_39_56.119221/model-00013-1.61449-0.18627-1.60711-0.21000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 6s 188ms/step - loss: 1.6071 - categorical_accuracy: 0.2059 - val_loss: 1.6072 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_39_56.119221/model-00014-1.60715-0.20588-1.60718-0.21000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 6s 191ms/step - loss: 1.6081 - categorical_accuracy: 0.2059 - val_loss: 1.6072 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_39_56.119221/model-00015-1.60814-0.20588-1.60719-0.21000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 6s 190ms/step - loss: 1.6087 - categorical_accuracy: 0.2157 - val_loss: 1.6072 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_39_56.119221/model-00016-1.60874-0.21569-1.60716-0.21000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 1.6094 - categorical_accuracy: 0.2190 - val_loss: 1.6072 - val_categorical_accuracy: 0.2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_39_56.119221/model-00017-1.60938-0.21895-1.60718-0.21000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 6s 189ms/step - loss: 1.6048 - categorical_accuracy: 0.2418 - val_loss: 1.6071 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_39_56.119221/model-00018-1.60481-0.24183-1.60715-0.21000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 6s 183ms/step - loss: 1.6114 - categorical_accuracy: 0.1863 - val_loss: 1.6072 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_39_56.119221/model-00019-1.61139-0.18627-1.60716-0.21000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 1.6093 - categorical_accuracy: 0.2092 - val_loss: 1.6072 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_39_56.119221/model-00020-1.60933-0.20915-1.60717-0.21000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d2(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2e : Resize to 120*120, agumentation, flipped images, normalisation, cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(16, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv1\", input_shape=(30, 120, ..., strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv2\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5b\", strides=(1, 1, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 30, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 30, 60, 60, 32)    13856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 15, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 15, 30, 30, 64)    55360     \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 15, 30, 30, 64)    110656    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 7, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 7, 15, 15, 128)    221312    \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 7, 15, 15, 128)    442496    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 3, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 3, 7, 7, 256)      884992    \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 3, 7, 7, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPaddin (None, 3, 9, 9, 256)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 5,862,597\n",
      "Trainable params: 5,862,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 40s 1s/step - loss: 1.6239 - categorical_accuracy: 0.1935 - val_loss: 1.6249 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_42_40.379231/model-00001-1.62455-0.19005-1.62486-0.21000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 6s 176ms/step - loss: 1.6081 - categorical_accuracy: 0.2353 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_42_40.379231/model-00002-1.60813-0.23529-1.60800-0.21000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 174ms/step - loss: 1.6074 - categorical_accuracy: 0.2353 - val_loss: 1.6343 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_42_40.379231/model-00003-1.60740-0.23529-1.63431-0.23000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 7s 207ms/step - loss: 1.6097 - categorical_accuracy: 0.1765 - val_loss: 1.6383 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_42_40.379231/model-00004-1.60966-0.17647-1.63834-0.18000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 6s 165ms/step - loss: 1.6168 - categorical_accuracy: 0.1601 - val_loss: 1.6411 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_42_40.379231/model-00005-1.61680-0.16013-1.64109-0.21000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 7s 206ms/step - loss: 1.6150 - categorical_accuracy: 0.1993 - val_loss: 1.6308 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_42_40.379231/model-00006-1.61496-0.19935-1.63077-0.21000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 6s 172ms/step - loss: 1.6125 - categorical_accuracy: 0.1961 - val_loss: 1.6254 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_42_40.379231/model-00007-1.61248-0.19608-1.62536-0.21000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 1.6106 - categorical_accuracy: 0.1993 - val_loss: 1.6214 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_42_40.379231/model-00008-1.61055-0.19935-1.62140-0.21000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 1.6104 - categorical_accuracy: 0.1830 - val_loss: 1.6208 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_42_40.379231/model-00009-1.61038-0.18301-1.62083-0.21000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 1.6158 - categorical_accuracy: 0.1307 - val_loss: 1.6202 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_42_40.379231/model-00010-1.61576-0.13072-1.62024-0.21000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 6s 174ms/step - loss: 1.6102 - categorical_accuracy: 0.2386 - val_loss: 1.6194 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_42_40.379231/model-00011-1.61019-0.23856-1.61938-0.21000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 1.6085 - categorical_accuracy: 0.1961 - val_loss: 1.6193 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_42_40.379231/model-00012-1.60850-0.19608-1.61928-0.21000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.6087 - categorical_accuracy: 0.2190 - val_loss: 1.6192 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_42_40.379231/model-00013-1.60872-0.21895-1.61916-0.21000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 6s 186ms/step - loss: 1.6083 - categorical_accuracy: 0.2288 - val_loss: 1.6194 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_42_40.379231/model-00014-1.60827-0.22876-1.61936-0.21000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 6s 177ms/step - loss: 1.6079 - categorical_accuracy: 0.2157 - val_loss: 1.6194 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_42_40.379231/model-00015-1.60788-0.21569-1.61941-0.21000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 1.6081 - categorical_accuracy: 0.2026 - val_loss: 1.6192 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_42_40.379231/model-00016-1.60809-0.20261-1.61921-0.21000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 6s 191ms/step - loss: 1.6059 - categorical_accuracy: 0.2222 - val_loss: 1.6192 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_42_40.379231/model-00017-1.60586-0.22222-1.61922-0.21000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 6s 177ms/step - loss: 1.6099 - categorical_accuracy: 0.2092 - val_loss: 1.6192 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_42_40.379231/model-00018-1.60995-0.20915-1.61924-0.21000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 6s 187ms/step - loss: 1.6143 - categorical_accuracy: 0.1471 - val_loss: 1.6192 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_42_40.379231/model-00019-1.61430-0.14706-1.61924-0.21000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 6s 191ms/step - loss: 1.6115 - categorical_accuracy: 0.1797 - val_loss: 1.6192 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_42_40.379231/model-00020-1.61150-0.17974-1.61921-0.21000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d2(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2f : Resize to 120*120, agumentation, flipped images, normalisation, cropping, edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(16, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv1\", input_shape=(30, 120, ..., strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv2\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5b\", strides=(1, 1, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 30, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 30, 60, 60, 32)    13856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 15, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 15, 30, 30, 64)    55360     \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 15, 30, 30, 64)    110656    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 7, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 7, 15, 15, 128)    221312    \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 7, 15, 15, 128)    442496    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 3, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 3, 7, 7, 256)      884992    \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 3, 7, 7, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPaddin (None, 3, 9, 9, 256)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 5,862,597\n",
      "Trainable params: 5,862,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 44s 1s/step - loss: 1.6120 - categorical_accuracy: 0.2102 - val_loss: 11.9868 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_45_24.174074/model-00001-1.61211-0.20714-11.98684-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 6s 177ms/step - loss: 1.6185 - categorical_accuracy: 0.2549 - val_loss: 1.7776 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_45_24.174074/model-00002-1.61849-0.25490-1.77758-0.19000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 1.6083 - categorical_accuracy: 0.1667 - val_loss: 1.9700 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_45_24.174074/model-00003-1.60831-0.16667-1.97000-0.18000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 7s 210ms/step - loss: 1.5933 - categorical_accuracy: 0.2059 - val_loss: 2.0429 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_45_24.174074/model-00004-1.59326-0.20588-2.04286-0.22000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 7s 213ms/step - loss: 1.6466 - categorical_accuracy: 0.1863 - val_loss: 1.9681 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_45_24.174074/model-00005-1.64657-0.18627-1.96815-0.22000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 7s 197ms/step - loss: 1.6132 - categorical_accuracy: 0.2124 - val_loss: 1.8820 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_45_24.174074/model-00006-1.61316-0.21242-1.88202-0.22000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 7s 210ms/step - loss: 1.6152 - categorical_accuracy: 0.1699 - val_loss: 1.8719 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_45_24.174074/model-00007-1.61521-0.16993-1.87190-0.22000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 7s 219ms/step - loss: 1.6107 - categorical_accuracy: 0.1699 - val_loss: 1.8645 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_45_24.174074/model-00008-1.61066-0.16993-1.86448-0.22000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 1.6069 - categorical_accuracy: 0.1536 - val_loss: 1.8700 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_45_24.174074/model-00009-1.60687-0.15359-1.87001-0.22000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 7s 212ms/step - loss: 1.6105 - categorical_accuracy: 0.1830 - val_loss: 1.8689 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_45_24.174074/model-00010-1.61050-0.18301-1.86889-0.22000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 8s 224ms/step - loss: 1.6086 - categorical_accuracy: 0.2124 - val_loss: 1.8670 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_45_24.174074/model-00011-1.60858-0.21242-1.86695-0.22000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 1.6118 - categorical_accuracy: 0.1830 - val_loss: 1.8660 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_45_24.174074/model-00012-1.61177-0.18301-1.86598-0.22000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.6126 - categorical_accuracy: 0.1895 - val_loss: 1.8658 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_45_24.174074/model-00013-1.61258-0.18954-1.86581-0.22000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.6118 - categorical_accuracy: 0.1863 - val_loss: 1.8643 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_45_24.174074/model-00014-1.61178-0.18627-1.86426-0.22000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 7s 217ms/step - loss: 1.6087 - categorical_accuracy: 0.1830 - val_loss: 1.8645 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_45_24.174074/model-00015-1.60868-0.18301-1.86451-0.22000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 7s 209ms/step - loss: 1.6075 - categorical_accuracy: 0.2190 - val_loss: 1.8643 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_45_24.174074/model-00016-1.60752-0.21895-1.86431-0.22000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 7s 200ms/step - loss: 1.6078 - categorical_accuracy: 0.2190 - val_loss: 1.8643 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_45_24.174074/model-00017-1.60776-0.21895-1.86433-0.22000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 1.6049 - categorical_accuracy: 0.2222 - val_loss: 1.8645 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_45_24.174074/model-00018-1.60493-0.22222-1.86451-0.22000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 7s 216ms/step - loss: 1.6135 - categorical_accuracy: 0.1797 - val_loss: 1.8643 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_45_24.174074/model-00019-1.61353-0.17974-1.86435-0.22000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 7s 220ms/step - loss: 1.6081 - categorical_accuracy: 0.1993 - val_loss: 1.8640 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_45_24.174074/model-00020-1.60812-0.19935-1.86396-0.22000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d2(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3a : Resize to 120*120,  No agumentation, No flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 30, 120, 120, 16)  6928      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 40, 40, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 40, 40, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 929,461\n",
      "Trainable params: 928,437\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 26s 760ms/step - loss: 2.0576 - categorical_accuracy: 0.2892 - val_loss: 5.0192 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_48_25.184784/model-00001-2.06901-0.28808-5.01923-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 4s 107ms/step - loss: 2.1142 - categorical_accuracy: 0.2941 - val_loss: 9.7407 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_48_25.184784/model-00002-2.11419-0.29412-9.74067-0.23000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 2.2670 - categorical_accuracy: 0.2353 - val_loss: 3.2265 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_48_25.184784/model-00003-2.26705-0.23529-3.22650-0.16000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 4s 123ms/step - loss: 2.0248 - categorical_accuracy: 0.3529 - val_loss: 4.2291 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_48_25.184784/model-00004-2.02481-0.35294-4.22906-0.16000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 4s 122ms/step - loss: 1.7502 - categorical_accuracy: 0.2941 - val_loss: 2.1105 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_48_25.184784/model-00005-1.75018-0.29412-2.11048-0.31000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 4s 116ms/step - loss: 2.0282 - categorical_accuracy: 0.2647 - val_loss: 8.8249 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_48_25.184784/model-00006-2.02816-0.26471-8.82490-0.17000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 3s 102ms/step - loss: 1.9073 - categorical_accuracy: 0.3333 - val_loss: 3.4074 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_48_25.184784/model-00007-1.90728-0.33333-3.40737-0.21000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 3s 103ms/step - loss: 1.9111 - categorical_accuracy: 0.3235 - val_loss: 1.9341 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_48_25.184784/model-00008-1.91108-0.32353-1.93409-0.24000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 1.8167 - categorical_accuracy: 0.3235 - val_loss: 1.5979 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_48_25.184784/model-00009-1.81670-0.32353-1.59789-0.25000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 5s 135ms/step - loss: 1.6990 - categorical_accuracy: 0.3235 - val_loss: 1.6198 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_48_25.184784/model-00010-1.69901-0.32353-1.61977-0.28000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 5s 137ms/step - loss: 1.7620 - categorical_accuracy: 0.3529 - val_loss: 2.0583 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_48_25.184784/model-00011-1.76203-0.35294-2.05833-0.22000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 5s 138ms/step - loss: 1.8838 - categorical_accuracy: 0.3137 - val_loss: 2.3716 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_48_25.184784/model-00012-1.88384-0.31373-2.37165-0.22000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 1.7689 - categorical_accuracy: 0.3039 - val_loss: 3.0822 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_48_25.184784/model-00013-1.76893-0.30392-3.08225-0.23000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 5s 137ms/step - loss: 1.8690 - categorical_accuracy: 0.2745 - val_loss: 1.9421 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_48_25.184784/model-00014-1.86902-0.27451-1.94209-0.25000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 5s 140ms/step - loss: 1.6192 - categorical_accuracy: 0.3725 - val_loss: 1.5335 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_48_25.184784/model-00015-1.61921-0.37255-1.53347-0.34000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 5s 138ms/step - loss: 1.7434 - categorical_accuracy: 0.3039 - val_loss: 1.4134 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_48_25.184784/model-00016-1.74336-0.30392-1.41338-0.42000.h5\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 141ms/step - loss: 1.6328 - categorical_accuracy: 0.3235 - val_loss: 1.3974 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_48_25.184784/model-00017-1.63283-0.32353-1.39743-0.43000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 5s 145ms/step - loss: 1.6698 - categorical_accuracy: 0.2745 - val_loss: 1.4373 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_48_25.184784/model-00018-1.66982-0.27451-1.43726-0.41000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 1.6766 - categorical_accuracy: 0.3725 - val_loss: 1.4797 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_48_25.184784/model-00019-1.67660-0.37255-1.47974-0.42000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 5s 141ms/step - loss: 1.7473 - categorical_accuracy: 0.3039 - val_loss: 1.4574 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_48_25.184784/model-00020-1.74730-0.30392-1.45737-0.46000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator()\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d3(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3b : Resize to 120*120,   agumentation, No flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 30, 120, 120, 16)  6928      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 40, 40, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 40, 40, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 929,461\n",
      "Trainable params: 928,437\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 33s 968ms/step - loss: 2.0259 - categorical_accuracy: 0.3245 - val_loss: 6.9701 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_50_16.316011/model-00001-2.04276-0.31599-6.97008-0.20000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 1.9068 - categorical_accuracy: 0.3137 - val_loss: 5.7957 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_50_16.316011/model-00002-1.90684-0.31373-5.79573-0.18000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 168ms/step - loss: 2.2127 - categorical_accuracy: 0.2647 - val_loss: 2.2881 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_50_16.316011/model-00003-2.21270-0.26471-2.28813-0.39000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 1.8377 - categorical_accuracy: 0.3431 - val_loss: 2.8585 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_50_16.316011/model-00004-1.83770-0.34314-2.85848-0.34000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 1.8096 - categorical_accuracy: 0.3971 - val_loss: 2.7257 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_50_16.316011/model-00005-1.80965-0.39706-2.72570-0.38000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 1.6500 - categorical_accuracy: 0.3676 - val_loss: 1.1602 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_50_16.316011/model-00006-1.64996-0.36765-1.16015-0.52000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 6s 172ms/step - loss: 1.7321 - categorical_accuracy: 0.3971 - val_loss: 1.5239 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_50_16.316011/model-00007-1.73214-0.39706-1.52390-0.40000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 6s 169ms/step - loss: 1.5334 - categorical_accuracy: 0.3971 - val_loss: 2.0541 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_50_16.316011/model-00008-1.53341-0.39706-2.05407-0.31000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 6s 164ms/step - loss: 1.4767 - categorical_accuracy: 0.4167 - val_loss: 1.7865 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_50_16.316011/model-00009-1.47665-0.41667-1.78645-0.32000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 1.6362 - categorical_accuracy: 0.4118 - val_loss: 1.5283 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_50_16.316011/model-00010-1.63617-0.41176-1.52830-0.35000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 6s 171ms/step - loss: 1.7075 - categorical_accuracy: 0.3775 - val_loss: 1.4677 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_50_16.316011/model-00011-1.70752-0.37745-1.46773-0.38000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 6s 180ms/step - loss: 1.7881 - categorical_accuracy: 0.2990 - val_loss: 1.1966 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_50_16.316011/model-00012-1.78812-0.29902-1.19657-0.45000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 6s 162ms/step - loss: 1.3688 - categorical_accuracy: 0.4706 - val_loss: 1.1351 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_50_16.316011/model-00013-1.36883-0.47059-1.13510-0.48000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 1.3979 - categorical_accuracy: 0.4510 - val_loss: 1.1015 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_50_16.316011/model-00014-1.39792-0.45098-1.10147-0.51000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 5s 162ms/step - loss: 1.4141 - categorical_accuracy: 0.4314 - val_loss: 1.0760 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_50_16.316011/model-00015-1.41411-0.43137-1.07603-0.50000.h5\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 6s 173ms/step - loss: 1.5890 - categorical_accuracy: 0.3775 - val_loss: 1.5777 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_50_16.316011/model-00016-1.58900-0.37745-1.57772-0.36000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 6s 170ms/step - loss: 1.4130 - categorical_accuracy: 0.4608 - val_loss: 1.4423 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_50_16.316011/model-00017-1.41300-0.46078-1.44233-0.38000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 1.6017 - categorical_accuracy: 0.3137 - val_loss: 1.1397 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_50_16.316011/model-00018-1.60174-0.31373-1.13965-0.50000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 1.5842 - categorical_accuracy: 0.3775 - val_loss: 0.9955 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_50_16.316011/model-00019-1.58415-0.37745-0.99548-0.61000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 6s 170ms/step - loss: 1.4634 - categorical_accuracy: 0.4902 - val_loss: 0.9609 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_50_16.316011/model-00020-1.46343-0.49020-0.96094-0.62000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d3(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3c : Resize to 120*120,  agumentation, flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 10\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 30, 120, 120, 16)  6928      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 40, 40, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 40, 40, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 929,461\n",
      "Trainable params: 928,437\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  Source path =  ./Project_data/val ; batch size = 10\n",
      "./Project_data/train ; batch size = 10\n",
      "67/67 [==============================] - 39s 575ms/step - loss: 2.0557 - categorical_accuracy: 0.2962 - val_loss: 2.3495 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_52_37.183439/model-00001-2.05886-0.29462-2.34949-0.25000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 11s 164ms/step - loss: 1.9500 - categorical_accuracy: 0.3250 - val_loss: 3.8812 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_52_37.183439/model-00002-1.95003-0.32504-3.88119-0.21000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 11s 167ms/step - loss: 1.8074 - categorical_accuracy: 0.3449 - val_loss: 8.3546 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_52_37.183439/model-00003-1.80737-0.34494-8.35460-0.18000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 12s 179ms/step - loss: 1.7849 - categorical_accuracy: 0.3068 - val_loss: 3.5334 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_52_37.183439/model-00004-1.78491-0.30680-3.53335-0.15000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 1.5105 - categorical_accuracy: 0.3765 - val_loss: 1.1159 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_52_37.183439/model-00005-1.51054-0.37645-1.11590-0.47000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 12s 180ms/step - loss: 1.2289 - categorical_accuracy: 0.4942 - val_loss: 1.8201 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_52_37.183439/model-00006-1.22891-0.49420-1.82008-0.36000.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 12s 174ms/step - loss: 1.3360 - categorical_accuracy: 0.4594 - val_loss: 1.1516 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_52_37.183439/model-00007-1.33595-0.45937-1.15156-0.51000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 11s 171ms/step - loss: 1.3067 - categorical_accuracy: 0.4743 - val_loss: 1.1880 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_52_37.183439/model-00008-1.30667-0.47430-1.18796-0.48000.h5\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 12s 178ms/step - loss: 1.1481 - categorical_accuracy: 0.5207 - val_loss: 1.0318 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_52_37.183439/model-00009-1.14806-0.52073-1.03183-0.58000.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 12s 175ms/step - loss: 1.0384 - categorical_accuracy: 0.5804 - val_loss: 1.0895 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_52_37.183439/model-00010-1.03841-0.58043-1.08951-0.58000.h5\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 1.1862 - categorical_accuracy: 0.5141 - val_loss: 0.8389 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_52_37.183439/model-00011-1.18619-0.51410-0.83886-0.66000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 13s 197ms/step - loss: 0.9704 - categorical_accuracy: 0.6202 - val_loss: 0.7591 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_52_37.183439/model-00012-0.97039-0.62023-0.75907-0.66000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 14s 204ms/step - loss: 0.9577 - categorical_accuracy: 0.6186 - val_loss: 0.7943 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_52_37.183439/model-00013-0.95767-0.61857-0.79429-0.68000.h5\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 14s 211ms/step - loss: 0.9854 - categorical_accuracy: 0.5904 - val_loss: 0.8224 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_52_37.183439/model-00014-0.98541-0.59038-0.82243-0.68000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 13s 200ms/step - loss: 0.7984 - categorical_accuracy: 0.6816 - val_loss: 0.7368 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_52_37.183439/model-00015-0.79843-0.68159-0.73682-0.72000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 14s 212ms/step - loss: 0.8576 - categorical_accuracy: 0.6667 - val_loss: 0.6656 - val_categorical_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_52_37.183439/model-00016-0.85755-0.66667-0.66565-0.75000.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 14s 207ms/step - loss: 0.9028 - categorical_accuracy: 0.6186 - val_loss: 0.6981 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_52_37.183439/model-00017-0.90275-0.61857-0.69809-0.75000.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 14s 204ms/step - loss: 0.9631 - categorical_accuracy: 0.6070 - val_loss: 0.7379 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_52_37.183439/model-00018-0.96313-0.60697-0.73785-0.73000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 15s 217ms/step - loss: 0.7894 - categorical_accuracy: 0.6700 - val_loss: 0.6748 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_52_37.183439/model-00019-0.78935-0.66998-0.67478-0.75000.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 15s 218ms/step - loss: 0.7970 - categorical_accuracy: 0.6683 - val_loss: 0.6357 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_52_37.183439/model-00020-0.79703-0.66833-0.63573-0.77000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d3(input_shape, num_classes)\n",
    "\n",
    "batch_size = 10\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3d : Resize to 120*120,  agumentation, flipped images, normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 10\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 30, 120, 120, 16)  6928      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 40, 40, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 40, 40, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 929,461\n",
      "Trainable params: 928,437\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/train ; batch size = 10\n",
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "67/67 [==============================] - 43s 647ms/step - loss: 1.6757 - categorical_accuracy: 0.3925 - val_loss: 10.1544 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2121_57_21.165248/model-00001-1.68678-0.38964-10.15440-0.37000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 13s 190ms/step - loss: 1.3581 - categorical_accuracy: 0.5008 - val_loss: 10.5852 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2121_57_21.165248/model-00002-1.35815-0.50083-10.58518-0.32000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 14s 206ms/step - loss: 1.1130 - categorical_accuracy: 0.5439 - val_loss: 9.5579 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2121_57_21.165248/model-00003-1.11302-0.54395-9.55792-0.40000.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 14s 213ms/step - loss: 1.0168 - categorical_accuracy: 0.5589 - val_loss: 8.3289 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2121_57_21.165248/model-00004-1.01678-0.55887-8.32886-0.44000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 13s 198ms/step - loss: 0.9039 - categorical_accuracy: 0.5937 - val_loss: 8.8274 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2121_57_21.165248/model-00005-0.90390-0.59370-8.82735-0.42000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 14s 203ms/step - loss: 0.8796 - categorical_accuracy: 0.6202 - val_loss: 9.0585 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2121_57_21.165248/model-00006-0.87963-0.62023-9.05852-0.42000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 13s 197ms/step - loss: 0.7924 - categorical_accuracy: 0.6584 - val_loss: 7.9558 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2121_57_21.165248/model-00007-0.79239-0.65837-7.95581-0.47000.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 14s 209ms/step - loss: 0.7410 - categorical_accuracy: 0.6816 - val_loss: 9.5097 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2121_57_21.165248/model-00008-0.74104-0.68159-9.50968-0.41000.h5\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 14s 210ms/step - loss: 0.5998 - categorical_accuracy: 0.7446 - val_loss: 8.7440 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2121_57_21.165248/model-00009-0.59984-0.74461-8.74402-0.45000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 14s 205ms/step - loss: 0.6721 - categorical_accuracy: 0.7164 - val_loss: 9.2423 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2121_57_21.165248/model-00010-0.67213-0.71642-9.24229-0.42000.h5\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 14s 206ms/step - loss: 0.5822 - categorical_accuracy: 0.7363 - val_loss: 9.5097 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2121_57_21.165248/model-00011-0.58217-0.73632-9.50968-0.41000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 14s 214ms/step - loss: 0.5411 - categorical_accuracy: 0.7695 - val_loss: 9.1873 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2121_57_21.165248/model-00012-0.54110-0.76949-9.18731-0.43000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 13s 199ms/step - loss: 0.6722 - categorical_accuracy: 0.7330 - val_loss: 9.0261 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2121_57_21.165248/model-00013-0.67224-0.73300-9.02613-0.44000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 13s 196ms/step - loss: 0.5676 - categorical_accuracy: 0.7562 - val_loss: 9.1883 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2121_57_21.165248/model-00014-0.56760-0.75622-9.18834-0.43000.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 14s 205ms/step - loss: 0.5467 - categorical_accuracy: 0.7678 - val_loss: 9.1274 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2121_57_21.165248/model-00015-0.54672-0.76783-9.12738-0.43000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 15s 218ms/step - loss: 0.5150 - categorical_accuracy: 0.7761 - val_loss: 9.3195 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2121_57_21.165248/model-00016-0.51501-0.77612-9.31948-0.42000.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 13s 201ms/step - loss: 0.5455 - categorical_accuracy: 0.7761 - val_loss: 9.1724 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2121_57_21.165248/model-00017-0.54545-0.77612-9.17243-0.43000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 14s 216ms/step - loss: 0.5745 - categorical_accuracy: 0.7745 - val_loss: 9.3027 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2121_57_21.165248/model-00018-0.57448-0.77446-9.30272-0.42000.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 13s 198ms/step - loss: 0.5057 - categorical_accuracy: 0.7944 - val_loss: 9.3485 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2121_57_21.165248/model-00019-0.50573-0.79436-9.34850-0.42000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 14s 203ms/step - loss: 0.5345 - categorical_accuracy: 0.7778 - val_loss: 9.3485 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2121_57_21.165248/model-00020-0.53448-0.77778-9.34850-0.42000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d3(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3e : Resize to 120*120,  agumentation, flipped images, normalisation,  cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 10\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 30, 120, 120, 16)  6928      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 40, 40, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 40, 40, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 929,461\n",
      "Trainable params: 928,437\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path = Source path =  ./Project_data/train ; batch size = 10\n",
      " ./Project_data/val ; batch size = 10\n",
      "67/67 [==============================] - 44s 651ms/step - loss: 2.1600 - categorical_accuracy: 0.2600 - val_loss: 10.2617 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_02_27.244563/model-00001-2.16378-0.26043-10.26169-0.22000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 13s 200ms/step - loss: 2.1479 - categorical_accuracy: 0.2587 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_02_27.244563/model-00002-2.14792-0.25871-12.41093-0.23000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 13s 198ms/step - loss: 1.9318 - categorical_accuracy: 0.2703 - val_loss: 11.9274 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_02_27.244563/model-00003-1.93178-0.27032-11.92739-0.26000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 12s 181ms/step - loss: 1.7600 - categorical_accuracy: 0.3118 - val_loss: 11.9274 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_02_27.244563/model-00004-1.75999-0.31177-11.92739-0.26000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 14s 205ms/step - loss: 1.6809 - categorical_accuracy: 0.3167 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_02_27.244563/model-00005-1.68094-0.31675-12.24975-0.24000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 13s 200ms/step - loss: 1.5568 - categorical_accuracy: 0.3466 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_02_27.244563/model-00006-1.55684-0.34660-12.41093-0.23000.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 14s 215ms/step - loss: 1.4909 - categorical_accuracy: 0.4196 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_02_27.244563/model-00007-1.49093-0.41957-12.24975-0.24000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 13s 189ms/step - loss: 1.4987 - categorical_accuracy: 0.4030 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_02_27.244563/model-00008-1.49867-0.40299-12.24975-0.24000.h5\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 1.4286 - categorical_accuracy: 0.4395 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_02_27.244563/model-00009-1.42857-0.43947-12.24975-0.24000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 14s 209ms/step - loss: 1.4077 - categorical_accuracy: 0.4345 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_02_27.244563/model-00010-1.40767-0.43449-12.24975-0.24000.h5\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 14s 204ms/step - loss: 1.4748 - categorical_accuracy: 0.3964 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_02_27.244563/model-00011-1.47483-0.39635-12.24975-0.24000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 12s 186ms/step - loss: 1.4274 - categorical_accuracy: 0.4262 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_02_27.244563/model-00012-1.42741-0.42620-12.24975-0.24000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 14s 202ms/step - loss: 1.3807 - categorical_accuracy: 0.4295 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_02_27.244563/model-00013-1.38071-0.42952-12.24975-0.24000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 13s 201ms/step - loss: 1.4316 - categorical_accuracy: 0.4096 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_02_27.244563/model-00014-1.43159-0.40962-12.24975-0.24000.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 14s 212ms/step - loss: 1.4203 - categorical_accuracy: 0.4179 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_02_27.244563/model-00015-1.42030-0.41791-12.24975-0.24000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 13s 194ms/step - loss: 1.3845 - categorical_accuracy: 0.4395 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_02_27.244563/model-00016-1.38453-0.43947-12.24975-0.24000.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 13s 189ms/step - loss: 1.3109 - categorical_accuracy: 0.4527 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_02_27.244563/model-00017-1.31091-0.45274-12.24975-0.24000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 14s 216ms/step - loss: 1.3556 - categorical_accuracy: 0.4262 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_02_27.244563/model-00018-1.35565-0.42620-12.24975-0.24000.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 13s 194ms/step - loss: 1.3653 - categorical_accuracy: 0.4511 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_02_27.244563/model-00019-1.36532-0.45108-12.24975-0.24000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 13s 196ms/step - loss: 1.4192 - categorical_accuracy: 0.4030 - val_loss: 12.2498 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_02_27.244563/model-00020-1.41921-0.40299-12.24975-0.24000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d3(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3f : Resize to 120*120,  agumentation, flipped images, normalisation, cropping, edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 10\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 30, 120, 120, 16)  6928      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 40, 40, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 40, 40, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 929,461\n",
      "Trainable params: 928,437\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "Source path =  ./Project_data/train ; batch size = 10\n",
      "67/67 [==============================] - 49s 729ms/step - loss: 1.4047 - categorical_accuracy: 0.3756 - val_loss: 11.8905 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_07_26.449958/model-00001-1.40491-0.37607-11.89046-0.25000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 15s 220ms/step - loss: 1.1593 - categorical_accuracy: 0.5340 - val_loss: 8.5508 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_07_26.449958/model-00002-1.15928-0.53400-8.55077-0.47000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 1.0332 - categorical_accuracy: 0.6003 - val_loss: 11.3355 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_07_26.449958/model-00003-1.03320-0.60033-11.33554-0.28000.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 16s 243ms/step - loss: 0.9572 - categorical_accuracy: 0.6219 - val_loss: 9.9932 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_07_26.449958/model-00004-0.95720-0.62189-9.99322-0.38000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 16s 234ms/step - loss: 0.8203 - categorical_accuracy: 0.6716 - val_loss: 10.7991 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_07_26.449958/model-00005-0.82029-0.67164-10.79913-0.33000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 16s 234ms/step - loss: 0.7070 - categorical_accuracy: 0.6833 - val_loss: 11.1288 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_07_26.449958/model-00006-0.70698-0.68325-11.12882-0.30000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 15s 219ms/step - loss: 0.6941 - categorical_accuracy: 0.7098 - val_loss: 10.6840 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_07_26.449958/model-00007-0.69409-0.70978-10.68399-0.33000.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 16s 235ms/step - loss: 0.6164 - categorical_accuracy: 0.7114 - val_loss: 11.4655 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_07_26.449958/model-00008-0.61639-0.71144-11.46548-0.28000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 14s 215ms/step - loss: 0.5968 - categorical_accuracy: 0.7562 - val_loss: 11.9092 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_07_26.449958/model-00009-0.59678-0.75622-11.90918-0.26000.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 15s 226ms/step - loss: 0.5238 - categorical_accuracy: 0.7910 - val_loss: 10.0091 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_07_26.449958/model-00010-0.52380-0.79104-10.00909-0.34000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 15s 224ms/step - loss: 0.5839 - categorical_accuracy: 0.7662 - val_loss: 10.5103 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_07_26.449958/model-00011-0.58393-0.76617-10.51028-0.31000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 15s 224ms/step - loss: 0.6365 - categorical_accuracy: 0.7579 - val_loss: 11.3120 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_07_26.449958/model-00012-0.63651-0.75788-11.31202-0.29000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 16s 232ms/step - loss: 0.5244 - categorical_accuracy: 0.7811 - val_loss: 10.6303 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_07_26.449958/model-00013-0.52441-0.78109-10.63029-0.32000.h5\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 15s 227ms/step - loss: 0.6042 - categorical_accuracy: 0.7645 - val_loss: 10.9256 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_07_26.449958/model-00014-0.60415-0.76451-10.92562-0.31000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 15s 231ms/step - loss: 0.4564 - categorical_accuracy: 0.7960 - val_loss: 10.8879 - val_categorical_accuracy: 0.3100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_07_26.449958/model-00015-0.45636-0.79602-10.88795-0.31000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 15s 223ms/step - loss: 0.5416 - categorical_accuracy: 0.7728 - val_loss: 10.7817 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_07_26.449958/model-00016-0.54161-0.77280-10.78175-0.31000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 15s 229ms/step - loss: 0.5810 - categorical_accuracy: 0.7595 - val_loss: 10.9265 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_07_26.449958/model-00017-0.58102-0.75954-10.92646-0.31000.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 15s 222ms/step - loss: 0.5594 - categorical_accuracy: 0.7479 - val_loss: 10.9424 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_07_26.449958/model-00018-0.55937-0.74793-10.94240-0.29000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 15s 230ms/step - loss: 0.5959 - categorical_accuracy: 0.7529 - val_loss: 10.9642 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_07_26.449958/model-00019-0.59592-0.75290-10.96415-0.29000.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 15s 218ms/step - loss: 0.4766 - categorical_accuracy: 0.7960 - val_loss: 10.9944 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_07_26.449958/model-00020-0.47662-0.79602-10.99440-0.30000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d3(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4a : Resize to 120*120,  No agumentation, No flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 90\n",
      "# epochs = 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "Source path =  ./Project_data/val ; batch size = 90\n",
      "Source path =  ./Project_data/train ; batch size = 90\n",
      "8/8 [==============================] - 26s 3s/step - loss: 2.2082 - categorical_accuracy: 0.2345 - val_loss: 1.4782 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_54_52.925487/model-00001-2.25286-0.22926-1.47824-0.33000.h5\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.5098 - categorical_accuracy: 0.3409 - val_loss: 1.8553 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_54_52.925487/model-00002-1.50976-0.34091-1.85528-0.20000.h5\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.4082 - categorical_accuracy: 0.3788 - val_loss: 2.1802 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_54_52.925487/model-00003-1.40824-0.37879-2.18019-0.20000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 5s 573ms/step - loss: 1.3246 - categorical_accuracy: 0.3836 - val_loss: 1.4174 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_54_52.925487/model-00004-1.39342-0.36111-1.41744-0.40000.h5\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.5630 - categorical_accuracy: 0.2917 - val_loss: 1.3387 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_54_52.925487/model-00005-1.56302-0.29167-1.33873-0.35000.h5\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 1.3304 - categorical_accuracy: 0.4167 - val_loss: 1.6484 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_54_52.925487/model-00006-1.33043-0.41667-1.64843-0.25000.h5\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 2.0385 - categorical_accuracy: 0.2917 - val_loss: 1.8207 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_54_52.925487/model-00007-2.03852-0.29167-1.82072-0.20000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.4933 - categorical_accuracy: 0.3333 - val_loss: 1.6126 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_54_52.925487/model-00008-1.49334-0.33333-1.61259-0.35000.h5\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 1.7015 - categorical_accuracy: 0.1667 - val_loss: 1.5275 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_54_52.925487/model-00009-1.70145-0.16667-1.52752-0.25000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 1.4576 - categorical_accuracy: 0.3333 - val_loss: 1.2325 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_54_52.925487/model-00010-1.45761-0.33333-1.23253-0.40000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator()\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d4(input_shape, num_classes)\n",
    "\n",
    "batch_size = 90\n",
    "num_epochs = 10\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4b : Resize to 120*120,  agumentation, No flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 50\n",
      "# epochs = 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_5 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "Source path =  ./Project_data/train ; batch size = 50\n",
      "Source path =  ./Project_data/val ; batch size = 50\n",
      "14/14 [==============================] - 33s 2s/step - loss: 2.0553 - categorical_accuracy: 0.2291 - val_loss: 1.5846 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2123_00_03.869014/model-00001-2.08225-0.22700-1.58463-0.30000.h5\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 8s 594ms/step - loss: 1.5820 - categorical_accuracy: 0.2555 - val_loss: 1.5652 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2123_00_03.869014/model-00002-1.58205-0.25549-1.56520-0.43000.h5\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 9s 656ms/step - loss: 1.5663 - categorical_accuracy: 0.3132 - val_loss: 1.5406 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2123_00_03.869014/model-00003-1.56634-0.31319-1.54062-0.39000.h5\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 9s 640ms/step - loss: 1.5074 - categorical_accuracy: 0.3022 - val_loss: 1.4637 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2123_00_03.869014/model-00004-1.50738-0.30220-1.46365-0.35000.h5\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 9s 618ms/step - loss: 1.3264 - categorical_accuracy: 0.4341 - val_loss: 1.3242 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2123_00_03.869014/model-00005-1.32641-0.43407-1.32416-0.39000.h5\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 9s 627ms/step - loss: 1.4257 - categorical_accuracy: 0.3846 - val_loss: 1.6070 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2123_00_03.869014/model-00006-1.42574-0.38462-1.60701-0.31000.h5\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 10s 689ms/step - loss: 1.3611 - categorical_accuracy: 0.4011 - val_loss: 1.2537 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2123_00_03.869014/model-00007-1.36112-0.40110-1.25373-0.48000.h5\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 9s 619ms/step - loss: 1.2781 - categorical_accuracy: 0.4176 - val_loss: 1.2370 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2123_00_03.869014/model-00008-1.27811-0.41758-1.23701-0.52000.h5\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 9s 617ms/step - loss: 1.1630 - categorical_accuracy: 0.5220 - val_loss: 2.0248 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2123_00_03.869014/model-00009-1.16298-0.52198-2.02485-0.32000.h5\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 9s 626ms/step - loss: 1.1293 - categorical_accuracy: 0.5247 - val_loss: 1.2289 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2123_00_03.869014/model-00010-1.12934-0.52473-1.22895-0.50000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d4(input_shape, num_classes)\n",
    "\n",
    "batch_size = 50\n",
    "num_epochs = 10\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4c : Resize to 120*120,  agumentation,  flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 30\n",
      "# epochs = 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_13 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "Source path =  ./Project_data/train ; batch size = 30\n",
      "Source path =  ./Project_data/val ; batch size = 30\n",
      "23/23 [==============================] - 39s 2s/step - loss: 1.8885 - categorical_accuracy: 0.2794 - val_loss: 1.4772 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2123_03_52.487540/model-00001-1.90538-0.27300-1.47719-0.28000.h5\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 1.5493 - categorical_accuracy: 0.2899 - val_loss: 1.7572 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2123_03_52.487540/model-00002-1.54925-0.28986-1.75721-0.30000.h5\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 4s 178ms/step - loss: 1.6312 - categorical_accuracy: 0.2029 - val_loss: 1.4681 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2123_03_52.487540/model-00003-1.63117-0.20290-1.46810-0.20000.h5\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 4s 188ms/step - loss: 1.5177 - categorical_accuracy: 0.3092 - val_loss: 2.7249 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2123_03_52.487540/model-00004-1.51767-0.30918-2.72490-0.25000.h5\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 5s 220ms/step - loss: 1.5391 - categorical_accuracy: 0.2947 - val_loss: 1.5052 - val_categorical_accuracy: 0.2750\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2123_03_52.487540/model-00005-1.53908-0.29469-1.50523-0.27500.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 5s 198ms/step - loss: 1.5284 - categorical_accuracy: 0.2899 - val_loss: 1.4060 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2123_03_52.487540/model-00006-1.52835-0.28986-1.40602-0.30000.h5\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 4s 173ms/step - loss: 1.4752 - categorical_accuracy: 0.3043 - val_loss: 1.4763 - val_categorical_accuracy: 0.2750\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2123_03_52.487540/model-00007-1.47524-0.30435-1.47627-0.27500.h5\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 1.4490 - categorical_accuracy: 0.3913 - val_loss: 1.3351 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2123_03_52.487540/model-00008-1.44901-0.39130-1.33512-0.37500.h5\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 5s 198ms/step - loss: 1.5220 - categorical_accuracy: 0.3188 - val_loss: 1.4831 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2123_03_52.487540/model-00009-1.52202-0.31884-1.48306-0.40000.h5\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 4s 177ms/step - loss: 1.4250 - categorical_accuracy: 0.3768 - val_loss: 1.3581 - val_categorical_accuracy: 0.4750\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2123_03_52.487540/model-00010-1.42505-0.37681-1.35807-0.47500.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d4(input_shape, num_classes)\n",
    "\n",
    "batch_size = 30\n",
    "num_epochs = 10\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4d : Resize to 120*120,  agumentation, No flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 40\n",
      "# epochs = 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_17 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "Source path =  ./Project_data/train ; batch size = 40\n",
      "Source path =  ./Project_data/val ; batch size = 40\n",
      "17/17 [==============================] - 35s 2s/step - loss: 2.1257 - categorical_accuracy: 0.2260 - val_loss: 1.5702 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2123_11_50.641986/model-00001-2.13875-0.22624-1.57019-0.44000.h5\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.5261 - categorical_accuracy: 0.3184 - val_loss: 1.4787 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2123_11_50.641986/model-00002-1.52613-0.31841-1.47872-0.30000.h5\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.3811 - categorical_accuracy: 0.3848 - val_loss: 1.4465 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2123_11_50.641986/model-00003-1.38761-0.38283-1.44646-0.35000.h5\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 15s 903ms/step - loss: 1.3315 - categorical_accuracy: 0.4087 - val_loss: 1.4391 - val_categorical_accuracy: 0.3667\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2123_11_50.641986/model-00004-1.33148-0.40867-1.43911-0.36667.h5\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 16s 947ms/step - loss: 1.1736 - categorical_accuracy: 0.4947 - val_loss: 1.3551 - val_categorical_accuracy: 0.4167\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2123_11_50.641986/model-00005-1.17239-0.49521-1.35512-0.41667.h5\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 15s 861ms/step - loss: 1.0766 - categorical_accuracy: 0.5588 - val_loss: 1.5101 - val_categorical_accuracy: 0.3833\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2123_11_50.641986/model-00006-1.07656-0.55882-1.51011-0.38333.h5\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 14s 838ms/step - loss: 0.9791 - categorical_accuracy: 0.5744 - val_loss: 1.7059 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2123_11_50.641986/model-00007-0.97911-0.57439-1.70590-0.35000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 15s 874ms/step - loss: 0.8199 - categorical_accuracy: 0.6592 - val_loss: 1.4384 - val_categorical_accuracy: 0.3167\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2123_11_50.641986/model-00008-0.81985-0.65917-1.43838-0.31667.h5\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 14s 829ms/step - loss: 0.8155 - categorical_accuracy: 0.6696 - val_loss: 1.3038 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2123_11_50.641986/model-00009-0.81553-0.66955-1.30381-0.40000.h5\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 14s 810ms/step - loss: 0.7782 - categorical_accuracy: 0.7128 - val_loss: 0.7777 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2123_11_50.641986/model-00010-0.77823-0.71280-0.77775-0.70000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, crop=False)\n",
    "val_gen = DataGenerator(crop=False)\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d4(input_shape, num_classes)\n",
    "\n",
    "batch_size = 40\n",
    "num_epochs = 10\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4e : Resize to 120*120,  agumentation, flipped images, normalisation, cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 42s 1s/step - loss: 1.7862 - categorical_accuracy: 0.2597 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_23_29.778726/model-00001-1.79459-0.26345-12.41093-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 6s 183ms/step - loss: 1.5856 - categorical_accuracy: 0.3497 - val_loss: 11.1863 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_23_29.778726/model-00002-1.58564-0.34967-11.18625-0.29000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 184ms/step - loss: 1.5143 - categorical_accuracy: 0.3235 - val_loss: 11.9239 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_23_29.778726/model-00003-1.51434-0.32353-11.92390-0.24000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 7s 207ms/step - loss: 1.4596 - categorical_accuracy: 0.4379 - val_loss: 11.9732 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_23_29.778726/model-00004-1.45957-0.43791-11.97320-0.25000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 7s 209ms/step - loss: 1.3611 - categorical_accuracy: 0.4575 - val_loss: 10.3550 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_23_29.778726/model-00005-1.36105-0.45752-10.35501-0.35000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 1.1823 - categorical_accuracy: 0.5033 - val_loss: 10.3328 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_23_29.778726/model-00006-1.18229-0.50327-10.33281-0.35000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 7s 206ms/step - loss: 1.2272 - categorical_accuracy: 0.5261 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_23_29.778726/model-00007-1.22716-0.52614-12.41093-0.23000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 1.3433 - categorical_accuracy: 0.4216 - val_loss: 10.4525 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_23_29.778726/model-00008-1.34334-0.42157-10.45253-0.34000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 7s 206ms/step - loss: 1.1297 - categorical_accuracy: 0.5327 - val_loss: 10.7233 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_23_29.778726/model-00009-1.12970-0.53268-10.72334-0.33000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 1.0739 - categorical_accuracy: 0.5882 - val_loss: 10.3622 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_23_29.778726/model-00010-1.07389-0.58824-10.36222-0.35000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 1.0442 - categorical_accuracy: 0.6078 - val_loss: 10.4768 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_23_29.778726/model-00011-1.04419-0.60784-10.47676-0.35000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 7s 191ms/step - loss: 0.9718 - categorical_accuracy: 0.5784 - val_loss: 10.3156 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_23_29.778726/model-00012-0.97175-0.57843-10.31558-0.36000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 0.9057 - categorical_accuracy: 0.6699 - val_loss: 10.3156 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_23_29.778726/model-00013-0.90573-0.66993-10.31558-0.36000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 7s 217ms/step - loss: 1.0807 - categorical_accuracy: 0.6013 - val_loss: 10.9551 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_23_29.778726/model-00014-1.08075-0.60131-10.95511-0.32000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 7s 193ms/step - loss: 0.9136 - categorical_accuracy: 0.6340 - val_loss: 10.8786 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_23_29.778726/model-00015-0.91362-0.63399-10.87859-0.32000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 6s 187ms/step - loss: 0.9170 - categorical_accuracy: 0.6503 - val_loss: 10.6197 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_23_29.778726/model-00016-0.91705-0.65033-10.61973-0.33000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 7s 195ms/step - loss: 0.8749 - categorical_accuracy: 0.6601 - val_loss: 10.3160 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_23_29.778726/model-00017-0.87489-0.66013-10.31597-0.36000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 0.9467 - categorical_accuracy: 0.6111 - val_loss: 10.4522 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_23_29.778726/model-00018-0.94675-0.61111-10.45221-0.35000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 0.8816 - categorical_accuracy: 0.6765 - val_loss: 10.4901 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_23_29.778726/model-00019-0.88163-0.67647-10.49010-0.34000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 0.8582 - categorical_accuracy: 0.6275 - val_loss: 10.7998 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_23_29.778726/model-00020-0.85819-0.62745-10.79982-0.33000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d4(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4f : Resize to 120*120,  agumentation, flipped images, normalisation, cropping, edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 47s 1s/step - loss: 1.8523 - categorical_accuracy: 0.2328 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_26_23.431341/model-00001-1.86216-0.22474-12.41093-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 7s 219ms/step - loss: 1.6057 - categorical_accuracy: 0.2484 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_26_23.431341/model-00002-1.60565-0.24837-12.41093-0.23000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 8s 242ms/step - loss: 1.6127 - categorical_accuracy: 0.2157 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_26_23.431341/model-00003-1.61273-0.21569-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 8s 236ms/step - loss: 1.5600 - categorical_accuracy: 0.2647 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_26_23.431341/model-00004-1.56004-0.26471-12.41093-0.23000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 7s 217ms/step - loss: 1.5321 - categorical_accuracy: 0.3301 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_26_23.431341/model-00005-1.53207-0.33007-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 1.5498 - categorical_accuracy: 0.3366 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_26_23.431341/model-00006-1.54980-0.33660-12.41093-0.23000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 8s 225ms/step - loss: 1.5062 - categorical_accuracy: 0.3137 - val_loss: 12.4064 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_26_23.431341/model-00007-1.50624-0.31373-12.40644-0.23000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 1.5591 - categorical_accuracy: 0.3072 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_26_23.431341/model-00008-1.55905-0.30719-12.41093-0.23000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 8s 233ms/step - loss: 1.4512 - categorical_accuracy: 0.3693 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_26_23.431341/model-00009-1.45116-0.36928-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 7s 208ms/step - loss: 1.3989 - categorical_accuracy: 0.4052 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_26_23.431341/model-00010-1.39888-0.40523-12.41093-0.23000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 8s 238ms/step - loss: 1.3816 - categorical_accuracy: 0.3987 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_26_23.431341/model-00011-1.38165-0.39869-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 8s 234ms/step - loss: 1.3998 - categorical_accuracy: 0.4118 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_26_23.431341/model-00012-1.39983-0.41176-12.41093-0.23000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 8s 233ms/step - loss: 1.3263 - categorical_accuracy: 0.4412 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_26_23.431341/model-00013-1.32627-0.44118-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 8s 233ms/step - loss: 1.3768 - categorical_accuracy: 0.3987 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_26_23.431341/model-00014-1.37683-0.39869-12.41093-0.23000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 8s 246ms/step - loss: 1.3343 - categorical_accuracy: 0.4412 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_26_23.431341/model-00015-1.33425-0.44118-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 8s 243ms/step - loss: 1.2987 - categorical_accuracy: 0.4869 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_26_23.431341/model-00016-1.29874-0.48693-12.41093-0.23000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 8s 230ms/step - loss: 1.3019 - categorical_accuracy: 0.4575 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_26_23.431341/model-00017-1.30189-0.45752-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 7s 214ms/step - loss: 1.3219 - categorical_accuracy: 0.4771 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_26_23.431341/model-00018-1.32187-0.47712-12.41093-0.23000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 1.3829 - categorical_accuracy: 0.4085 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_26_23.431341/model-00019-1.38294-0.40850-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 8s 240ms/step - loss: 1.4071 - categorical_accuracy: 0.3660 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_26_23.431341/model-00020-1.40712-0.36601-12.41093-0.23000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d4(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 4g : Resize to 120*120,  agumentation, flipped images, No normalisation, cropping, edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/train Source path =  ./Project_data/val ; batch size = 20\n",
      "; batch size = 20\n",
      "34/34 [==============================] - 54s 2s/step - loss: 1.8184 - categorical_accuracy: 0.2575 - val_loss: 4.9224 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_49_34.968496/model-00001-1.82500-0.25842-4.92243-0.22000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 9s 262ms/step - loss: 1.6118 - categorical_accuracy: 0.2810 - val_loss: 1.8029 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_49_34.968496/model-00002-1.61177-0.28105-1.80290-0.22000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 10s 282ms/step - loss: 1.6043 - categorical_accuracy: 0.2320 - val_loss: 3.9067 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_49_34.968496/model-00003-1.60434-0.23203-3.90674-0.22000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 9s 254ms/step - loss: 1.5384 - categorical_accuracy: 0.3072 - val_loss: 6.0873 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_49_34.968496/model-00004-1.53843-0.30719-6.08726-0.22000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 9s 258ms/step - loss: 1.5152 - categorical_accuracy: 0.3105 - val_loss: 5.2582 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_49_34.968496/model-00005-1.51520-0.31046-5.25819-0.16000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 8s 245ms/step - loss: 1.5385 - categorical_accuracy: 0.3072 - val_loss: 7.4924 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_49_34.968496/model-00006-1.53848-0.30719-7.49241-0.22000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 10s 281ms/step - loss: 1.4942 - categorical_accuracy: 0.3007 - val_loss: 6.8632 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_49_34.968496/model-00007-1.49417-0.30065-6.86325-0.26000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 10s 295ms/step - loss: 1.5006 - categorical_accuracy: 0.3529 - val_loss: 6.3283 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_49_34.968496/model-00008-1.50064-0.35294-6.32827-0.23000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 9s 272ms/step - loss: 1.4316 - categorical_accuracy: 0.3987 - val_loss: 7.1439 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_49_34.968496/model-00009-1.43160-0.39869-7.14388-0.23000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 8s 249ms/step - loss: 1.4436 - categorical_accuracy: 0.3889 - val_loss: 6.9663 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_49_34.968496/model-00010-1.44356-0.38889-6.96633-0.23000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 9s 272ms/step - loss: 1.5062 - categorical_accuracy: 0.3693 - val_loss: 7.2006 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_49_34.968496/model-00011-1.50616-0.36928-7.20055-0.23000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 9s 259ms/step - loss: 1.5033 - categorical_accuracy: 0.3235 - val_loss: 7.0267 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_49_34.968496/model-00012-1.50335-0.32353-7.02673-0.23000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 9s 278ms/step - loss: 1.4653 - categorical_accuracy: 0.3758 - val_loss: 7.2299 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_49_34.968496/model-00013-1.46530-0.37582-7.22992-0.23000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 9s 252ms/step - loss: 1.5106 - categorical_accuracy: 0.3562 - val_loss: 7.0995 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_49_34.968496/model-00014-1.51057-0.35621-7.09950-0.23000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 9s 265ms/step - loss: 1.4240 - categorical_accuracy: 0.3725 - val_loss: 7.0083 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_49_34.968496/model-00015-1.42399-0.37255-7.00832-0.23000.h5\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 8s 242ms/step - loss: 1.4066 - categorical_accuracy: 0.3954 - val_loss: 7.0784 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_49_34.968496/model-00016-1.40665-0.39542-7.07836-0.23000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 9s 258ms/step - loss: 1.4472 - categorical_accuracy: 0.3791 - val_loss: 7.1558 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_49_34.968496/model-00017-1.44721-0.37908-7.15582-0.23000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 9s 253ms/step - loss: 1.4193 - categorical_accuracy: 0.3856 - val_loss: 7.1740 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_49_34.968496/model-00018-1.41928-0.38562-7.17398-0.23000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 9s 275ms/step - loss: 1.4509 - categorical_accuracy: 0.3464 - val_loss: 7.1749 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_49_34.968496/model-00019-1.45085-0.34641-7.17490-0.23000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 9s 253ms/step - loss: 1.3558 - categorical_accuracy: 0.4412 - val_loss: 7.1396 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_49_34.968496/model-00020-1.35580-0.44118-7.13961-0.23000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=False, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d4(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5a : Resize to 120*120,  No agumentation, No flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 863,877\n",
      "Trainable params: 863,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 26s 769ms/step - loss: 12.6633 - categorical_accuracy: 0.2104 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_29_41.675097/model-00001-12.57732-0.21569-12.73329-0.21000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 4s 115ms/step - loss: 13.2737 - categorical_accuracy: 0.1765 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_29_41.675097/model-00002-13.27373-0.17647-12.73330-0.21000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 12.3256 - categorical_accuracy: 0.2353 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_29_41.675097/model-00003-12.32560-0.23529-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 4s 127ms/step - loss: 12.3285 - categorical_accuracy: 0.2353 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_29_41.675097/model-00004-12.32855-0.23529-12.41093-0.23000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 4s 106ms/step - loss: 12.0096 - categorical_accuracy: 0.2549 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_29_41.675097/model-00005-12.00956-0.25490-12.41093-0.23000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 4s 104ms/step - loss: 12.9577 - categorical_accuracy: 0.1961 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_29_41.675097/model-00006-12.95768-0.19608-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 4s 112ms/step - loss: 13.1157 - categorical_accuracy: 0.1863 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_29_41.675097/model-00007-13.11570-0.18627-12.41093-0.23000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 4s 118ms/step - loss: 13.5775 - categorical_accuracy: 0.1569 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_29_41.675097/model-00008-13.57753-0.15686-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 5s 139ms/step - loss: 12.3256 - categorical_accuracy: 0.2353 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_29_41.675097/model-00009-12.32560-0.23529-12.41093-0.23000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 5s 144ms/step - loss: 11.3775 - categorical_accuracy: 0.2941 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_29_41.675097/model-00010-11.37748-0.29412-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 5s 139ms/step - loss: 12.9577 - categorical_accuracy: 0.1961 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_29_41.675097/model-00011-12.95768-0.19608-12.41093-0.23000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 5s 143ms/step - loss: 13.4317 - categorical_accuracy: 0.1667 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_29_41.675097/model-00012-13.43175-0.16667-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 5s 144ms/step - loss: 13.4317 - categorical_accuracy: 0.1667 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_29_41.675097/model-00013-13.43175-0.16667-12.41093-0.23000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 5s 141ms/step - loss: 13.2737 - categorical_accuracy: 0.1765 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_29_41.675097/model-00014-13.27373-0.17647-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 5s 141ms/step - loss: 13.7478 - categorical_accuracy: 0.1471 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_29_41.675097/model-00015-13.74779-0.14706-12.41093-0.23000.h5\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 145ms/step - loss: 13.1157 - categorical_accuracy: 0.1863 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_29_41.675097/model-00016-13.11570-0.18627-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 5s 142ms/step - loss: 13.5898 - categorical_accuracy: 0.1569 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_29_41.675097/model-00017-13.58977-0.15686-12.41093-0.23000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 5s 143ms/step - loss: 12.4836 - categorical_accuracy: 0.2255 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_29_41.675097/model-00018-12.48362-0.22549-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 5s 142ms/step - loss: 12.1676 - categorical_accuracy: 0.2451 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_29_41.675097/model-00019-12.16758-0.24510-12.41093-0.23000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 5s 142ms/step - loss: 12.7997 - categorical_accuracy: 0.2059 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_29_41.675097/model-00020-12.79966-0.20588-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator()\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d5(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5b : Resize to 120*120,  agumentation, No flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 863,877\n",
      "Trainable params: 863,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 32s 949ms/step - loss: 12.7285 - categorical_accuracy: 0.2090 - val_loss: 12.9711 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_31_35.281471/model-00001-12.64414-0.21418-12.97112-0.15000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 6s 179ms/step - loss: 12.4836 - categorical_accuracy: 0.2255 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_31_35.281471/model-00002-12.48362-0.22549-12.73330-0.21000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 180ms/step - loss: 13.5898 - categorical_accuracy: 0.1569 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_31_35.281471/model-00003-13.58977-0.15686-12.73330-0.21000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 6s 177ms/step - loss: 13.6688 - categorical_accuracy: 0.1520 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_31_35.281471/model-00004-13.66878-0.15196-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 5s 143ms/step - loss: 13.1023 - categorical_accuracy: 0.1863 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_31_35.281471/model-00005-13.10227-0.18627-12.73330-0.21000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 6s 171ms/step - loss: 12.3980 - categorical_accuracy: 0.2304 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_31_35.281471/model-00006-12.39802-0.23039-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 5s 161ms/step - loss: 13.2521 - categorical_accuracy: 0.1765 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_31_35.281471/model-00007-13.25209-0.17647-12.73330-0.21000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 6s 179ms/step - loss: 12.4046 - categorical_accuracy: 0.2304 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_31_35.281471/model-00008-12.40461-0.23039-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 6s 185ms/step - loss: 12.4836 - categorical_accuracy: 0.2255 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_31_35.281471/model-00009-12.48362-0.22549-12.73330-0.21000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 6s 181ms/step - loss: 12.4836 - categorical_accuracy: 0.2255 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_31_35.281471/model-00010-12.48362-0.22549-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 6s 169ms/step - loss: 12.3256 - categorical_accuracy: 0.2353 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_31_35.281471/model-00011-12.32560-0.23529-12.73330-0.21000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 6s 168ms/step - loss: 12.1676 - categorical_accuracy: 0.2451 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_31_35.281471/model-00012-12.16758-0.24510-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 13.5898 - categorical_accuracy: 0.1569 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_31_35.281471/model-00013-13.58977-0.15686-12.73330-0.21000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 6s 173ms/step - loss: 13.1947 - categorical_accuracy: 0.1814 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_31_35.281471/model-00014-13.19472-0.18137-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 6s 166ms/step - loss: 13.2737 - categorical_accuracy: 0.1765 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_31_35.281471/model-00015-13.27373-0.17647-12.73330-0.21000.h5\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 6s 180ms/step - loss: 12.4996 - categorical_accuracy: 0.2206 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_31_35.281471/model-00016-12.49962-0.22059-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 6s 177ms/step - loss: 12.2466 - categorical_accuracy: 0.2402 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_31_35.281471/model-00017-12.24659-0.24020-12.73330-0.21000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 6s 171ms/step - loss: 12.6416 - categorical_accuracy: 0.2157 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_31_35.281471/model-00018-12.64164-0.21569-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 12.7207 - categorical_accuracy: 0.2108 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_31_35.281471/model-00019-12.72065-0.21078-12.73330-0.21000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 6s 173ms/step - loss: 13.7478 - categorical_accuracy: 0.1471 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_31_35.281471/model-00020-13.74779-0.14706-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d5(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5c : Resize to 120*120,  agumentation, flipped images, No normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 863,877\n",
      "Trainable params: 863,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 39s 1s/step - loss: 12.7549 - categorical_accuracy: 0.2063 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_34_00.297517/model-00001-12.80494-0.20312-12.73330-0.21000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 13.0630 - categorical_accuracy: 0.1895 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_34_00.297517/model-00002-13.06303-0.18954-12.73330-0.21000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 190ms/step - loss: 12.8523 - categorical_accuracy: 0.2026 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_34_00.297517/model-00003-12.85234-0.20261-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 13.2737 - categorical_accuracy: 0.1765 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_34_00.297517/model-00004-13.27373-0.17647-12.73330-0.21000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 7s 215ms/step - loss: 13.2737 - categorical_accuracy: 0.1765 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_34_00.297517/model-00005-13.27373-0.17647-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 7s 208ms/step - loss: 12.7191 - categorical_accuracy: 0.2092 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_34_00.297517/model-00006-12.71910-0.20915-12.73330-0.21000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 7s 208ms/step - loss: 12.7470 - categorical_accuracy: 0.2092 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_34_00.297517/model-00007-12.74700-0.20915-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 7s 218ms/step - loss: 12.0096 - categorical_accuracy: 0.2549 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_34_00.297517/model-00008-12.00956-0.25490-12.73330-0.21000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 7s 210ms/step - loss: 13.8015 - categorical_accuracy: 0.1438 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_34_00.297517/model-00009-13.80153-0.14379-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 13.2737 - categorical_accuracy: 0.1765 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_34_00.297517/model-00010-13.27373-0.17647-12.73330-0.21000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 7s 218ms/step - loss: 12.6943 - categorical_accuracy: 0.2124 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_34_00.297517/model-00011-12.69432-0.21242-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 12.4836 - categorical_accuracy: 0.2255 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_34_00.297517/model-00012-12.48362-0.22549-12.73330-0.21000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 6s 191ms/step - loss: 12.1676 - categorical_accuracy: 0.2451 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_34_00.297517/model-00013-12.16758-0.24510-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 7s 218ms/step - loss: 12.6953 - categorical_accuracy: 0.2092 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_34_00.297517/model-00014-12.69532-0.20915-12.73330-0.21000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 7s 207ms/step - loss: 12.4309 - categorical_accuracy: 0.2288 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_34_00.297517/model-00015-12.43095-0.22876-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 7s 216ms/step - loss: 12.8523 - categorical_accuracy: 0.2026 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_34_00.297517/model-00016-12.85234-0.20261-12.73330-0.21000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 13.2737 - categorical_accuracy: 0.1765 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_34_00.297517/model-00017-13.27373-0.17647-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 7s 208ms/step - loss: 12.6945 - categorical_accuracy: 0.2124 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_34_00.297517/model-00018-12.69450-0.21242-12.73330-0.21000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 7s 220ms/step - loss: 12.4340 - categorical_accuracy: 0.2255 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_34_00.297517/model-00019-12.43398-0.22549-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 7s 215ms/step - loss: 12.5890 - categorical_accuracy: 0.2190 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_34_00.297517/model-00020-12.58897-0.21895-12.73330-0.21000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d5(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5d : Resize to 120*120,  agumentation, flipped images, normalisation, No cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 863,877\n",
      "Trainable params: 863,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 41s 1s/step - loss: 1.6472 - categorical_accuracy: 0.2178 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_36_55.673460/model-00001-1.65032-0.21217-12.41093-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 6s 189ms/step - loss: 1.5888 - categorical_accuracy: 0.2614 - val_loss: 8.7788 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_36_55.673460/model-00002-1.58879-0.26144-8.77878-0.23000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 1.6041 - categorical_accuracy: 0.2157 - val_loss: 4.0235 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_36_55.673460/model-00003-1.60410-0.21569-4.02345-0.25000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 7s 207ms/step - loss: 1.6037 - categorical_accuracy: 0.2516 - val_loss: 9.9986 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_36_55.673460/model-00004-1.60373-0.25163-9.99860-0.18000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 7s 219ms/step - loss: 1.5491 - categorical_accuracy: 0.2876 - val_loss: 6.2645 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_36_55.673460/model-00005-1.54908-0.28758-6.26453-0.36000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 1.5083 - categorical_accuracy: 0.3529 - val_loss: 8.9215 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_36_55.673460/model-00006-1.50831-0.35294-8.92153-0.36000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 6s 185ms/step - loss: 1.4791 - categorical_accuracy: 0.3464 - val_loss: 9.6920 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_36_55.673460/model-00007-1.47913-0.34641-9.69197-0.39000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 1.3545 - categorical_accuracy: 0.4183 - val_loss: 9.0794 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_36_55.673460/model-00008-1.35454-0.41830-9.07940-0.42000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 1.3377 - categorical_accuracy: 0.3693 - val_loss: 7.0047 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_36_55.673460/model-00009-1.33769-0.36928-7.00467-0.52000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 7s 215ms/step - loss: 1.2744 - categorical_accuracy: 0.4673 - val_loss: 9.6709 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_36_55.673460/model-00010-1.27441-0.46732-9.67086-0.40000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 8s 224ms/step - loss: 1.2480 - categorical_accuracy: 0.4542 - val_loss: 9.4313 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_36_55.673460/model-00011-1.24805-0.45425-9.43131-0.40000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.2046 - categorical_accuracy: 0.5065 - val_loss: 9.4112 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_36_55.673460/model-00012-1.20464-0.50654-9.41120-0.40000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 1.1524 - categorical_accuracy: 0.5000 - val_loss: 9.0066 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_36_55.673460/model-00013-1.15244-0.50000-9.00660-0.42000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 6s 189ms/step - loss: 1.2207 - categorical_accuracy: 0.4739 - val_loss: 9.3730 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_36_55.673460/model-00014-1.22073-0.47386-9.37300-0.40000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 7s 218ms/step - loss: 1.0922 - categorical_accuracy: 0.5294 - val_loss: 9.4957 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_36_55.673460/model-00015-1.09217-0.52941-9.49572-0.39000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 7s 206ms/step - loss: 1.1996 - categorical_accuracy: 0.4477 - val_loss: 9.4374 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_36_55.673460/model-00016-1.19958-0.44771-9.43739-0.39000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 6s 190ms/step - loss: 1.1588 - categorical_accuracy: 0.4967 - val_loss: 9.4813 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_36_55.673460/model-00017-1.15883-0.49673-9.48133-0.39000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.2891 - categorical_accuracy: 0.4314 - val_loss: 9.4048 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_36_55.673460/model-00018-1.28909-0.43137-9.40477-0.40000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 7s 196ms/step - loss: 1.0779 - categorical_accuracy: 0.5850 - val_loss: 9.4188 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_36_55.673460/model-00019-1.07794-0.58497-9.41876-0.41000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 7s 196ms/step - loss: 1.2832 - categorical_accuracy: 0.4673 - val_loss: 9.3872 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_36_55.673460/model-00020-1.28324-0.46732-9.38722-0.41000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d5(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5e : Resize to 120*120,  agumentation, flipped images, normalisation, cropping, No edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 863,877\n",
      "Trainable params: 863,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 40s 1s/step - loss: 1.6260 - categorical_accuracy: 0.2016 - val_loss: 9.5488 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_39_49.545996/model-00001-1.62522-0.20664-9.54876-0.18000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 1.5888 - categorical_accuracy: 0.2712 - val_loss: 10.0854 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_39_49.545996/model-00002-1.58879-0.27124-10.08535-0.22000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 7s 208ms/step - loss: 1.5213 - categorical_accuracy: 0.3039 - val_loss: 11.4701 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_39_49.545996/model-00003-1.52134-0.30392-11.47012-0.23000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 6s 189ms/step - loss: 1.5586 - categorical_accuracy: 0.3301 - val_loss: 9.7992 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_39_49.545996/model-00004-1.55862-0.33007-9.79915-0.32000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.4901 - categorical_accuracy: 0.3366 - val_loss: 12.0286 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_39_49.545996/model-00005-1.49008-0.33660-12.02862-0.22000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 6s 179ms/step - loss: 1.4203 - categorical_accuracy: 0.3562 - val_loss: 10.3346 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_39_49.545996/model-00006-1.42031-0.35621-10.33456-0.33000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 7s 213ms/step - loss: 1.4565 - categorical_accuracy: 0.3693 - val_loss: 10.4382 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_39_49.545996/model-00007-1.45653-0.36928-10.43820-0.32000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 7s 215ms/step - loss: 1.3131 - categorical_accuracy: 0.4444 - val_loss: 10.7587 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_39_49.545996/model-00008-1.31312-0.44444-10.75871-0.30000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 1.3650 - categorical_accuracy: 0.4346 - val_loss: 10.6145 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_39_49.545996/model-00009-1.36505-0.43464-10.61453-0.32000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 7s 217ms/step - loss: 1.3558 - categorical_accuracy: 0.4216 - val_loss: 10.4348 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_39_49.545996/model-00010-1.35576-0.42157-10.43482-0.33000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 1.2342 - categorical_accuracy: 0.4869 - val_loss: 10.3179 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_39_49.545996/model-00011-1.23423-0.48693-10.31792-0.36000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 1.3025 - categorical_accuracy: 0.4967 - val_loss: 10.3196 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_39_49.545996/model-00012-1.30252-0.49673-10.31961-0.36000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 7s 220ms/step - loss: 1.2961 - categorical_accuracy: 0.4183 - val_loss: 10.3175 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_39_49.545996/model-00013-1.29606-0.41830-10.31752-0.36000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 1.2302 - categorical_accuracy: 0.4575 - val_loss: 10.3198 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_39_49.545996/model-00014-1.23017-0.45752-10.31981-0.36000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 7s 219ms/step - loss: 1.3058 - categorical_accuracy: 0.4477 - val_loss: 10.3255 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_39_49.545996/model-00015-1.30581-0.44771-10.32549-0.36000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 7s 200ms/step - loss: 1.2721 - categorical_accuracy: 0.4575 - val_loss: 10.3227 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_39_49.545996/model-00016-1.27207-0.45752-10.32265-0.36000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.1835 - categorical_accuracy: 0.5229 - val_loss: 10.3245 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_39_49.545996/model-00017-1.18347-0.52288-10.32447-0.36000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 7s 206ms/step - loss: 1.1870 - categorical_accuracy: 0.5392 - val_loss: 10.3232 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_39_49.545996/model-00018-1.18705-0.53922-10.32318-0.36000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 7s 191ms/step - loss: 1.2425 - categorical_accuracy: 0.4346 - val_loss: 10.3230 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_39_49.545996/model-00019-1.24249-0.43464-10.32301-0.36000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 1.2871 - categorical_accuracy: 0.4150 - val_loss: 10.3229 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_39_49.545996/model-00020-1.28709-0.41503-10.32285-0.36000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d5(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5f : Resize to 120*120, All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 863,877\n",
      "Trainable params: 863,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 47s 1s/step - loss: 1.6120 - categorical_accuracy: 0.1935 - val_loss: 8.1142 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_42_43.394553/model-00001-1.61146-0.19558-8.11422-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 7s 214ms/step - loss: 1.5764 - categorical_accuracy: 0.2582 - val_loss: 12.1885 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_42_43.394553/model-00002-1.57642-0.25817-12.18854-0.23000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 8s 245ms/step - loss: 1.5651 - categorical_accuracy: 0.2614 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_42_43.394553/model-00003-1.56513-0.26144-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 8s 244ms/step - loss: 1.5458 - categorical_accuracy: 0.3137 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_42_43.394553/model-00004-1.54578-0.31373-12.41093-0.23000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 8s 233ms/step - loss: 1.4490 - categorical_accuracy: 0.3529 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_42_43.394553/model-00005-1.44904-0.35294-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 8s 230ms/step - loss: 1.4577 - categorical_accuracy: 0.2941 - val_loss: 12.1257 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_42_43.394553/model-00006-1.45771-0.29412-12.12568-0.23000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 8s 232ms/step - loss: 1.4267 - categorical_accuracy: 0.3301 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_42_43.394553/model-00007-1.42673-0.33007-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 8s 234ms/step - loss: 1.3577 - categorical_accuracy: 0.4542 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_42_43.394553/model-00008-1.35767-0.45425-12.41093-0.23000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 7s 219ms/step - loss: 1.3708 - categorical_accuracy: 0.3464 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_42_43.394553/model-00009-1.37076-0.34641-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 8s 230ms/step - loss: 1.3474 - categorical_accuracy: 0.3856 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_42_43.394553/model-00010-1.34743-0.38562-12.41093-0.23000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 7s 220ms/step - loss: 1.3115 - categorical_accuracy: 0.4314 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_42_43.394553/model-00011-1.31148-0.43137-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 1.4023 - categorical_accuracy: 0.3562 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_42_43.394553/model-00012-1.40227-0.35621-12.41093-0.23000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 7s 213ms/step - loss: 1.2985 - categorical_accuracy: 0.4216 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_42_43.394553/model-00013-1.29849-0.42157-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 8s 230ms/step - loss: 1.3730 - categorical_accuracy: 0.3889 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_42_43.394553/model-00014-1.37296-0.38889-12.41093-0.23000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.3399 - categorical_accuracy: 0.3922 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_42_43.394553/model-00015-1.33991-0.39216-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 8s 222ms/step - loss: 1.3339 - categorical_accuracy: 0.4085 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_42_43.394553/model-00016-1.33390-0.40850-12.41093-0.23000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 8s 239ms/step - loss: 1.3429 - categorical_accuracy: 0.3791 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_42_43.394553/model-00017-1.34289-0.37908-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 7s 220ms/step - loss: 1.3523 - categorical_accuracy: 0.4085 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_42_43.394553/model-00018-1.35233-0.40850-12.41093-0.23000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 1.3093 - categorical_accuracy: 0.4085 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_42_43.394553/model-00019-1.30930-0.40850-12.41093-0.23000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 7s 219ms/step - loss: 1.3177 - categorical_accuracy: 0.4216 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_42_43.394553/model-00020-1.31771-0.42157-12.41093-0.23000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d5(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5g : Resize to 120*120, All except normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 863,877\n",
      "Trainable params: 863,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 52s 2s/step - loss: 12.4080 - categorical_accuracy: 0.2166 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2122_46_00.151324/model-00001-12.44940-0.21368-12.73330-0.21000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 8s 242ms/step - loss: 12.4423 - categorical_accuracy: 0.2222 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2018-10-2122_46_00.151324/model-00002-12.44231-0.22222-12.73330-0.21000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 8s 249ms/step - loss: 12.3783 - categorical_accuracy: 0.2320 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00003: saving model to model_init_2018-10-2122_46_00.151324/model-00003-12.37828-0.23203-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 8s 243ms/step - loss: 13.9992 - categorical_accuracy: 0.1307 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2018-10-2122_46_00.151324/model-00004-13.99916-0.13072-12.73330-0.21000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 9s 254ms/step - loss: 12.5363 - categorical_accuracy: 0.2222 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: saving model to model_init_2018-10-2122_46_00.151324/model-00005-12.53630-0.22222-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 9s 251ms/step - loss: 13.2336 - categorical_accuracy: 0.1765 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2018-10-2122_46_00.151324/model-00006-13.23358-0.17647-12.73330-0.21000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 9s 250ms/step - loss: 12.2729 - categorical_accuracy: 0.2386 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2018-10-2122_46_00.151324/model-00007-12.27293-0.23856-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 9s 255ms/step - loss: 13.3791 - categorical_accuracy: 0.1699 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2018-10-2122_46_00.151324/model-00008-13.37912-0.16993-12.73330-0.21000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 9s 264ms/step - loss: 12.3783 - categorical_accuracy: 0.2320 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2018-10-2122_46_00.151324/model-00009-12.37828-0.23203-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 9s 252ms/step - loss: 13.6424 - categorical_accuracy: 0.1536 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2018-10-2122_46_00.151324/model-00010-13.64244-0.15359-12.73330-0.21000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 8s 229ms/step - loss: 12.3783 - categorical_accuracy: 0.2320 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00011: saving model to model_init_2018-10-2122_46_00.151324/model-00011-12.37828-0.23203-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 8s 245ms/step - loss: 12.3525 - categorical_accuracy: 0.2320 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2018-10-2122_46_00.151324/model-00012-12.35248-0.23203-12.73330-0.21000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 9s 256ms/step - loss: 13.1157 - categorical_accuracy: 0.1863 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00013: saving model to model_init_2018-10-2122_46_00.151324/model-00013-13.11571-0.18627-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 9s 256ms/step - loss: 12.2203 - categorical_accuracy: 0.2418 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2018-10-2122_46_00.151324/model-00014-12.22026-0.24183-12.73330-0.21000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 9s 260ms/step - loss: 13.0630 - categorical_accuracy: 0.1895 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00015: saving model to model_init_2018-10-2122_46_00.151324/model-00015-13.06303-0.18954-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 9s 257ms/step - loss: 13.0104 - categorical_accuracy: 0.1928 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00016: saving model to model_init_2018-10-2122_46_00.151324/model-00016-13.01036-0.19281-12.73330-0.21000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 8s 232ms/step - loss: 12.0330 - categorical_accuracy: 0.2516 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00017: saving model to model_init_2018-10-2122_46_00.151324/model-00017-12.03296-0.25163-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 8s 242ms/step - loss: 13.0630 - categorical_accuracy: 0.1895 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00018: saving model to model_init_2018-10-2122_46_00.151324/model-00018-13.06303-0.18954-12.73329-0.21000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 8s 241ms/step - loss: 13.5371 - categorical_accuracy: 0.1601 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2018-10-2122_46_00.151324/model-00019-13.53709-0.16013-12.73330-0.21000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 8s 236ms/step - loss: 12.1169 - categorical_accuracy: 0.2484 - val_loss: 12.7333 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00020: saving model to model_init_2018-10-2122_46_00.151324/model-00020-12.11691-0.24837-12.73330-0.21000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=False, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d5(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5h : Resize to 120*120, All except normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=False, crop=True, edge=False)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d5(input_shape, num_classes)\n",
    "\n",
    "#batch_size = 20\n",
    "#num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
